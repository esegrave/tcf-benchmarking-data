{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import util\n",
    "\n",
    "proficiency_path = './data/tx/proficiency/'\n",
    "\n",
    "# import column maps\n",
    "map_files = [\n",
    "    '2019_CAMPSTAAR1_map.csv'\n",
    "    , '2019_CAMPSTAAR2_map.csv'\n",
    "    , '2019_CAMPSTAAR4_map.csv'\n",
    "    , '2019_CAMPSTAAR5_map.csv'\n",
    "    , '2018_CAMPSTAAR1_map.csv'\n",
    "    , '2018_CAMPSTAAR2_map.csv'\n",
    "    , '2018_CAMPSTAAR4_map.csv'\n",
    "    , '2018_CAMPSTAAR5_map.csv'\n",
    "    , '2017_CAMPSTAAR1_map.csv'\n",
    "    , '2017_CAMPSTAAR2_map.csv'\n",
    "    , '2017_CAMPSTAAR4_map.csv'\n",
    "    , '2017_CAMPSTAAR5_map.csv'\n",
    "    , '2016_CAMPSTAAR1_map.csv'\n",
    "    , '2016_CAMPSTAAR4_map.csv'\n",
    "    , '2015_CAMPSTAAR1_map.csv'\n",
    "    , '2015_CAMPSTAAR4_map.csv'\n",
    "    , '2014_CAMPSTAAR1_map.csv'\n",
    "    , '2014_CAMPSTAAR4_map.csv'\n",
    "    , '2013_CAMPSTAAR1_map.csv'\n",
    "    , '2013_CAMPSTAAR4_map.csv'\n",
    "]\n",
    "\n",
    "years = [x[:4] for x in map_files]\n",
    "filenames = [x[5:15] for x in map_files]\n",
    "\n",
    "df_map = pd.read_csv(proficiency_path + map_files[0])\n",
    "df_map['year'] = df_map.apply(lambda x: years[0], axis = 1)\n",
    "df_map['file'] = df_map.apply(lambda x: filenames[0], axis = 1)\n",
    "\n",
    "for i in range(1, len(map_files)):\n",
    "    temp = pd.read_csv(proficiency_path + map_files[i])\n",
    "    temp['year'] = temp.apply(lambda x: years[i], axis = 1)\n",
    "    temp['file'] = temp.apply(lambda x: filenames[i], axis = 1)\n",
    "    df_map = df_map.append(temp, ignore_index = True, sort = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import proficiency files\n",
    "proficiency_files = [\n",
    "    '2019_CAMPSTAAR1.txt'\n",
    "    , '2019_CAMPSTAAR2.txt'\n",
    "    , '2019_CAMPSTAAR4.txt'\n",
    "    , '2019_CAMPSTAAR5.txt'\n",
    "    , '2018_CAMPSTAAR1.txt'\n",
    "    , '2018_CAMPSTAAR2.txt'\n",
    "    , '2018_CAMPSTAAR4.txt'\n",
    "    , '2018_CAMPSTAAR5.txt'\n",
    "    , '2017_CAMPSTAAR1.txt'\n",
    "    , '2017_CAMPSTAAR2.txt'\n",
    "    , '2017_CAMPSTAAR4.txt'\n",
    "    , '2017_CAMPSTAAR5.txt'\n",
    "    , '2016_CAMPSTAAR1.txt'\n",
    "    , '2016_CAMPSTAAR4.txt'\n",
    "    , '2015_CAMPSTAAR1.txt'\n",
    "    , '2015_CAMPSTAAR4.txt'\n",
    "    , '2014_CAMPSTAAR1.txt'\n",
    "    , '2014_CAMPSTAAR4.txt'\n",
    "    , '2013_CAMPSTAAR1.txt'\n",
    "    , '2013_CAMPSTAAR4.txt'\n",
    "]\n",
    "\n",
    "years = [x[:4] for x in proficiency_files]\n",
    "filenames = [x[5:15] for x in proficiency_files]\n",
    "\n",
    "df = pd.read_csv(proficiency_path + proficiency_files[0])\n",
    "value_vars = list(df.columns)\n",
    "value_vars.remove('CAMPUS')\n",
    "df = pd.melt(df, id_vars = ['CAMPUS'], value_vars = value_vars, var_name='NAME', value_name='VALUE')\n",
    "df = df[df['VALUE'] != '.']\n",
    "df['year'] = df.apply(lambda x: years[0], axis = 1)\n",
    "df['file'] = df.apply(lambda x: filenames[0], axis = 1)\n",
    "\n",
    "for i in range(1, len(proficiency_files)):\n",
    "    temp = pd.read_csv(proficiency_path + proficiency_files[i])\n",
    "    value_vars = list(temp.columns)\n",
    "    value_vars.remove('CAMPUS')\n",
    "    temp = pd.melt(temp, id_vars = ['CAMPUS'], value_vars = value_vars, var_name='NAME', value_name='VALUE')\n",
    "    temp = temp[temp['VALUE'] != '.']\n",
    "    temp['year'] = temp.apply(lambda x: years[i], axis = 1)\n",
    "    temp['file'] = temp.apply(lambda x: filenames[i], axis = 1)\n",
    "    df = df.append(temp, ignore_index = True, sort = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import school info files\n",
    "school_files = [\n",
    "    '2019_CREF.txt'\n",
    "    , '2018_CREF.txt'\n",
    "    , '2017_CREF.txt'\n",
    "    , '2016_CREF.txt'\n",
    "    , '2015_CREF.txt'\n",
    "    , '2014_CREF.txt'\n",
    "    , '2013_CREF.txt'\n",
    "]\n",
    "\n",
    "years = [x[:4] for x in school_files]\n",
    "\n",
    "df_school = pd.read_csv(proficiency_path + school_files[0])\n",
    "df_school['year'] = df_school.apply(lambda x: years[0], axis = 1)\n",
    "\n",
    "for i in range(1, len(school_files)):\n",
    "    temp = pd.read_csv(proficiency_path + school_files[i])\n",
    "    temp['year'] = temp.apply(lambda x: years[i], axis = 1)\n",
    "    df_school = df_school.append(temp, ignore_index = True, sort = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119340601, 5)\n",
      "(71549592, 8)\n"
     ]
    }
   ],
   "source": [
    "# join column map to proficiency data, deliberately dropping rows we excluded from the column maps\n",
    "print(df.shape)\n",
    "df = df.merge(df_map, on = ['year', 'file', 'NAME'])\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(71549592, 8)\n",
      "(70877718, 8)\n"
     ]
    }
   ],
   "source": [
    "# drop First Administration records\n",
    "print(df.shape)\n",
    "df = df[~df.LABEL.str.contains(\"First Administration\")]\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70877718, 8)\n",
      "(42168458, 8)\n"
     ]
    }
   ],
   "source": [
    "# drop rate rows\n",
    "print(df.shape)\n",
    "df = df[~df.LABEL.str.contains('Rate')]\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42168458, 8)\n",
      "(23836924, 8)\n"
     ]
    }
   ],
   "source": [
    "# remove previous year's records, making exception for 2017 data coming from 2018 file\n",
    "print(df.shape)\n",
    "def filterYears(row):\n",
    "    if row['year'] != '2017' and row['LABEL'].find(str(int(row['year']) - 1)) > 0:\n",
    "        return 1\n",
    "    if row['year'] == '2017' and row['LABEL'].find(str(int(row['year']) + 1)) > 0:\n",
    "        return 1\n",
    "    return 0\n",
    "df['deleteFlag'] = df.apply(lambda x: filterYears(x), axis = 1)\n",
    "df = df[df['deleteFlag'] == 0]\n",
    "del df['deleteFlag']\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                       Grade 3\n",
      "264680                  Grade 4\n",
      "528368                  Grade 5\n",
      "7136794                 Grade 6\n",
      "7281150                 Grade 7\n",
      "7407810                 Grade 8\n",
      "11140857          EOC English I\n",
      "11259333         EOC English II\n",
      "11369581          EOC Algebra I\n",
      "11551769         EOC US History\n",
      "11657225            EOC Biology\n",
      "62677896      EOC Reading/ELA I\n",
      "62719932     EOC Reading/ELA II\n",
      "69164460          EOC Reading I\n",
      "69204766         EOC Reading II\n",
      "69240470        EOC Reading III\n",
      "69313764           EOC Geometry\n",
      "69353036         EOC Algebra II\n",
      "69376202          EOC Writing I\n",
      "69416594         EOC Writing II\n",
      "69452090        EOC Writing III\n",
      "69457072    EOC World Geography\n",
      "69495446      EOC World History\n",
      "69581752          EOC Chemistry\n",
      "69613826            EOC Physics\n",
      "Name: grade, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# parse grade level\n",
    "def parseGrade(row):\n",
    "    eocIndex = row['LABEL'].find('EOC')\n",
    "    if row['LABEL'].upper().find('GRADE 3') > 0:\n",
    "        return 'Grade 3'\n",
    "    if row['LABEL'].upper().find('GRADE 4') > 0:\n",
    "        return 'Grade 4'\n",
    "    if row['LABEL'].upper().find('GRADE 5') > 0:\n",
    "        return 'Grade 5'\n",
    "    if row['LABEL'].upper().find('GRADE 6') > 0:\n",
    "        return 'Grade 6'\n",
    "    if row['LABEL'].upper().find('GRADE 7') > 0:\n",
    "        return 'Grade 7'\n",
    "    if row['LABEL'].upper().find('GRADE 8') > 0:\n",
    "        return 'Grade 8'\n",
    "    if eocIndex > 0:\n",
    "        return row['LABEL'][eocIndex:]\n",
    "    return 'All Grades'\n",
    "\n",
    "df['grade'] = df.apply(lambda x: parseGrade(x), axis = 1)\n",
    "df['grade'] = df['grade'].str.replace(',', '')\n",
    "df['grade'] = df['grade'].str.replace('Denominator', '')\n",
    "df['grade'] = df['grade'].str.replace('Numerator', '')\n",
    "df['grade'] = df['grade'].str.strip()\n",
    "print(df['grade'].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                        All Students\n",
      "18204                African American\n",
      "32180                           White\n",
      "48072                        Hispanic\n",
      "66112                 American Indian\n",
      "69472               Two or more races\n",
      "80920                             ELL\n",
      "97792                           Asian\n",
      "106508               Pacific Islander\n",
      "108116                         Female\n",
      "126292                           Male\n",
      "144456                    Econ Disadv\n",
      "162564                     Special Ed\n",
      "180300                        At Risk\n",
      "228528            Continuous Enrollee\n",
      "246568                         Mobile\n",
      "13318011                      Migrant\n",
      "13320019                  Non-Migrant\n",
      "13338223                     Non-CATE\n",
      "13356415              Non-Econ Disadv\n",
      "13373991               Non-Special Ed\n",
      "13392175                  Non-At Risk\n",
      "13410263                      Non-ELL\n",
      "13428463     First-Year-Monitored-ELL\n",
      "13432063    Second-Year-Monitored-ELL\n",
      "14179015                         CATE\n",
      "16690413                Elective-CATE\n",
      "Name: group_state, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# parse group\n",
    "def parseGroup(row):\n",
    "    if row['LABEL'].upper().find('CONTINUOUS ENROLLEE') > 0:\n",
    "        return 'Continuous Enrollee'\n",
    "    if row['LABEL'].upper().find('MOBILE') > 0:\n",
    "        return 'Mobile'\n",
    "    if row['LABEL'].upper().find('NON-AT RISK') > 0:\n",
    "        return 'Non-At Risk'\n",
    "    if row['LABEL'].upper().find('NON-CATE') > 0:\n",
    "        return 'Non-CATE'\n",
    "    if row['LABEL'].upper().find('NON-ELL') > 0 or row['LABEL'].upper().find('NON-EL') > 0:\n",
    "        return 'Non-ELL'\n",
    "    if row['LABEL'].upper().find('NON-ECON DISADV') > 0:\n",
    "        return 'Non-Econ Disadv'\n",
    "    if row['LABEL'].upper().find('NON-MIGRANT') > 0:\n",
    "        return 'Non-Migrant'\n",
    "    if row['LABEL'].upper().find('NON-SPECIAL ED') > 0:\n",
    "        return 'Non-Special Ed'\n",
    "    if row['LABEL'].upper().find('FIRST-YEAR-MONITORED-ELL') > 0 or row['LABEL'].upper().find('FIRST-YEAR-MONITORED-EL') > 0:\n",
    "        return 'First-Year-Monitored-ELL'\n",
    "    if row['LABEL'].upper().find('SECOND-YEAR-MONITORED-ELL') > 0 or row['LABEL'].upper().find('SECOND-YEAR-MONITORED-EL') > 0:\n",
    "        return 'Second-Year-Monitored-ELL'\n",
    "    if row['LABEL'].upper().find('AFRICAN AMERICAN') > 0:\n",
    "        return 'African American'\n",
    "    if row['LABEL'].upper().find('ALL STUDENTS') > 0:\n",
    "        return 'All Students'\n",
    "    if row['LABEL'].upper().find('AMERICAN INDIAN') > 0:\n",
    "        return 'American Indian'\n",
    "    if row['LABEL'].upper().find('ASIAN') > 0:\n",
    "        return 'Asian'\n",
    "    if row['LABEL'].upper().find('FEMALE') > 0:\n",
    "        return 'Female'\n",
    "    if row['LABEL'].upper().find('MALE') > 0:\n",
    "        return 'Male'\n",
    "    if row['LABEL'].upper().find('AT RISK') > 0:\n",
    "        return 'At Risk'\n",
    "    if row['LABEL'].upper().find('ECON DISADV') > 0:\n",
    "        return 'Econ Disadv'\n",
    "    if row['LABEL'].upper().find('HISPANIC') > 0:\n",
    "        return 'Hispanic'\n",
    "    if row['LABEL'].upper().find('PACIFIC ISLANDER') > 0:\n",
    "        return 'Pacific Islander'\n",
    "    if row['LABEL'].upper().find('SPECIAL ED') > 0:\n",
    "        return 'Special Ed'\n",
    "    if row['LABEL'].upper().find('WHITE') > 0:\n",
    "        return 'White'\n",
    "    if row['LABEL'].upper().find('TWO OR MORE RACES') > 0:\n",
    "        return 'Two or more races'\n",
    "    if row['LABEL'].upper().find('ELECTIVE-CATE') > 0:\n",
    "        return 'Elective-CATE'\n",
    "    if row['LABEL'].upper().find('CATE') > 0:\n",
    "        return 'CATE'\n",
    "    if row['LABEL'].upper().find('MIGRANT') > 0:\n",
    "        return 'Migrant'\n",
    "    if row['LABEL'].upper().find('ELL') > 0 or row['LABEL'].upper().find('EL,') > 0:\n",
    "        return 'ELL'\n",
    "    return row['LABEL']\n",
    "        \n",
    "df['group_state'] = df.apply(lambda x: parseGroup(x), axis = 1)\n",
    "print(df['group_state'].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                     ELA\n",
      "776896               Math\n",
      "1817608           Science\n",
      "8179486    Social Studies\n",
      "Name: subject, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# parse subject\n",
    "def parseSubject(row):\n",
    "    if row['LABEL'].upper().find('MATH') > 0 or row['LABEL'].upper().find('ALGEBRA') > 0 or row['LABEL'].upper().find('GEOMETRY') > 0:\n",
    "        return 'Math'\n",
    "    if row['LABEL'].upper().find('READING') > 0 or row['LABEL'].upper().find('ELA') > 0 or row['LABEL'].upper().find('WRITING') > 0 or row['LABEL'].upper().find('ENGLISH') > 0:\n",
    "        return 'ELA'\n",
    "    if row['LABEL'].upper().find('SOCIAL STUDIES') > 0 or row['LABEL'].upper().find('HISTORY') > 0 or row['LABEL'].upper().find('GEOGRAPHY') > 0:\n",
    "        return 'Social Studies'\n",
    "    if row['LABEL'].upper().find('SCIENCE') > 0 or row['LABEL'].upper().find('BIOLOGY') > 0 or row['LABEL'].upper().find('PHYSICS') > 0 or row['LABEL'].upper().find('CHEMISTRY') > 0:\n",
    "        return 'Science'\n",
    "    return row['LABEL']\n",
    "\n",
    "df['subject'] = df.apply(lambda x: parseSubject(x), axis = 1)\n",
    "print(df['subject'].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15747651, 11)\n",
      "(8089273, 11)\n"
     ]
    }
   ],
   "source": [
    "# split dataset into numerator/denominator values\n",
    "df_num = df[df.LABEL.str.contains('Numerator')]\n",
    "print(df_num.shape)\n",
    "df_denom = df[df.LABEL.str.contains('Denominator')]\n",
    "print(df_denom.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4551              Approaches Grade Level\n",
      "9102                   Meets Grade Level\n",
      "13653                Masters Grade Level\n",
      "53379646    Phase-in 1 Level II or above\n",
      "Name: performance_level, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "# parse performance level\n",
    "def parsePerformance(row):\n",
    "    if row['LABEL'].upper().find('APPROACHES GRADE LEVEL') > 0:\n",
    "        return 'Approaches Grade Level'\n",
    "    if row['LABEL'].upper().find('MASTERS GRADE LEVEL') > 0:\n",
    "        return 'Masters Grade Level'\n",
    "    if row['LABEL'].upper().find('MEETS GRADE LEVEL') > 0:\n",
    "        return 'Meets Grade Level'\n",
    "    return 'Phase-in 1 Level II or above'\n",
    "\n",
    "df_num['performance_level'] = df_num.apply(lambda x: parsePerformance(x), axis = 1)\n",
    "print(df_num['performance_level'].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4551    0\n",
      "9102    1\n",
      "Name: proficient_tf, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# drop unneeded columns\n",
    "df_num = df_num[['CAMPUS', 'VALUE', 'year', 'grade', 'group_state', 'subject', 'performance_level']]\n",
    "df_num = df_num.rename(columns = {'VALUE': 'num_at_level'})\n",
    "\n",
    "def createProficientTF(row):\n",
    "    if row['performance_level'] == 'Approaches Grade Level':\n",
    "        return 0\n",
    "    if row['performance_level'] == 'Phase-in 1 Level II or above' or row['performance_level'] == 'Masters Grade Level' or row['performance_level'] == 'Meets Grade Level':\n",
    "        return 1\n",
    "df_num['proficient_tf'] = df_num.apply(lambda x: createProficientTF(x), axis = 1)\n",
    "print(df_num['proficient_tf'].drop_duplicates())\n",
    "\n",
    "df_denom = df_denom[['CAMPUS', 'VALUE', 'year', 'grade', 'group_state', 'subject']]\n",
    "df_denom = df_denom.rename(columns = {'VALUE': 'num_tested'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15747651, 8)\n",
      "(13871505, 8)\n"
     ]
    }
   ],
   "source": [
    "# roll up all results by subject/grade/group/year/campus/proficient_tf/performance_level\n",
    "print(df_num.shape)\n",
    "grouped_by = ['year', 'CAMPUS', 'subject', 'grade', 'group_state', 'proficient_tf', 'performance_level']\n",
    "# change suppressed values to 0, so they aren't integers\n",
    "df_num['num_at_level'] = [int(x) if int(x) >= 0 else 0 for x in df_num['num_at_level']]\n",
    "df_num = df_num.groupby(grouped_by, as_index = False)['num_at_level'].sum()\n",
    "print(df_num.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8089273, 6)\n",
      "(7158273, 6)\n"
     ]
    }
   ],
   "source": [
    "print(df_denom.shape)\n",
    "grouped_by.remove('proficient_tf')\n",
    "grouped_by.remove('performance_level')\n",
    "# change suppressed values to 0, so they aren't integers\n",
    "df_denom['num_tested'] = [int(x) if int(x) >= 0 else 0 for x in df_denom['num_tested']]\n",
    "df_denom = df_denom.groupby(grouped_by, as_index = False)['num_tested'].sum()\n",
    "print(df_denom.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13871505, 8)\n",
      "(7158273, 6)\n",
      "   year   CAMPUS subject          grade       group_state  proficient_tf  \\\n",
      "0  2013  1902001     ELA  EOC Reading I  African American              1   \n",
      "1  2013  1902001     ELA  EOC Reading I      All Students              1   \n",
      "2  2013  1902001     ELA  EOC Reading I             Asian              1   \n",
      "3  2013  1902001     ELA  EOC Reading I           At Risk              1   \n",
      "4  2013  1902001     ELA  EOC Reading I              CATE              1   \n",
      "\n",
      "              performance_level  num_at_level  num_tested  \n",
      "0  Phase-in 1 Level II or above             0           0  \n",
      "1  Phase-in 1 Level II or above            39          53  \n",
      "2  Phase-in 1 Level II or above             0           0  \n",
      "3  Phase-in 1 Level II or above            11          21  \n",
      "4  Phase-in 1 Level II or above             7          10  \n",
      "(13871505, 9)\n"
     ]
    }
   ],
   "source": [
    "# join num_at_level and num_tested values to each other\n",
    "print(df_num.shape)\n",
    "print(df_denom.shape)\n",
    "df_joined = df_num.merge(df_denom, on = ['CAMPUS', 'year', 'subject', 'grade', 'group_state'], how='inner')\n",
    "print(df_joined.head())\n",
    "print(df_joined.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change suppressed values back to 0\n",
    "def suppressNumAtLevel(row):\n",
    "    if row['num_at_level'] == 0 and row['num_tested'] == 0:\n",
    "        return 'N/A'\n",
    "    return row['num_at_level']\n",
    "\n",
    "def suppressNumTested(row):\n",
    "    if row['num_at_level'] == 0 and row['num_tested'] == 0:\n",
    "        return 'N/A'\n",
    "    return row['num_tested']\n",
    "\n",
    "df_joined['num_at_level'] = df_joined.apply(lambda x: suppressNumAtLevel(x), axis = 1)\n",
    "df_joined['num_tested'] = df_joined.apply(lambda x: suppressNumTested(x), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13871505, 9)\n",
      "(93924848, 12)\n",
      "   year  school_id subject          grade       group_state  proficient_tf  \\\n",
      "0  2013    1902001     ELA  EOC Reading I  African American              1   \n",
      "1  2013    1902001     ELA  EOC Reading I  African American              1   \n",
      "2  2013    1902001     ELA  EOC Reading I  African American              1   \n",
      "3  2013    1902001     ELA  EOC Reading I  African American              1   \n",
      "4  2013    1902001     ELA  EOC Reading I  African American              1   \n",
      "\n",
      "              performance_level num_at_level  num_tested      school  \\\n",
      "0  Phase-in 1 Level II or above          N/A           0  CAYUGA H S   \n",
      "1  Phase-in 1 Level II or above          N/A           0  CAYUGA H S   \n",
      "2  Phase-in 1 Level II or above          N/A           0  CAYUGA H S   \n",
      "3  Phase-in 1 Level II or above          N/A           0  CAYUGA H S   \n",
      "4  Phase-in 1 Level II or above          N/A           0  CAYUGA H S   \n",
      "\n",
      "   district_id    district  \n",
      "0         1902  CAYUGA ISD  \n",
      "1         1902  CAYUGA ISD  \n",
      "2         1902  CAYUGA ISD  \n",
      "3         1902  CAYUGA ISD  \n",
      "4         1902  CAYUGA ISD  \n"
     ]
    }
   ],
   "source": [
    "# join campus data file\n",
    "print(df_joined.shape)\n",
    "df_school = df_school[['CAMPUS', 'CAMPNAME', 'DISTRICT', 'DISTNAME']]\n",
    "df_joined = df_joined.merge(df_school, on = 'CAMPUS')\n",
    "df_joined = df_joined.rename(columns = {\n",
    "    'CAMPUS': 'school_id',\n",
    "    'CAMPNAME': 'school',\n",
    "    'DISTRICT': 'district_id',\n",
    "    'DISTNAME': 'district'\n",
    "})\n",
    "print(df_joined.shape)\n",
    "print(df_joined.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(93924848, 12)\n",
      "(23836924, 11)\n"
     ]
    }
   ],
   "source": [
    "# drop all non-proficiency rows\n",
    "print(df_joined.shape)\n",
    "df_joined = df_joined[df_joined.proficient_tf == 1]\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(71264898, 12)\n"
     ]
    }
   ],
   "source": [
    "# convert num_at_level and num_tested to float\n",
    "def toFloat(row, column):\n",
    "    try:\n",
    "        return float(row[column])\n",
    "    except:\n",
    "        return np.nan\n",
    "df_joined['num_tested'] = df_joined.apply(lambda x: toFloat(x, 'num_tested'), axis = 1)\n",
    "df_joined['num_at_level'] = df_joined.apply(lambda x: toFloat(x, 'num_at_level'), axis = 1)\n",
    "print(df_joined.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(71264898, 12)\n",
      "(45942206, 12)\n"
     ]
    }
   ],
   "source": [
    "# remove rows with no scores\n",
    "print(df_joined.shape)\n",
    "df_joined = df_joined[df_joined['num_at_level'] != 0]\n",
    "df_joined = df_joined.dropna(subset=['num_tested', 'num_at_level'])\n",
    "print(df_joined.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45942206, 12)\n",
      "(5294671, 11)\n"
     ]
    }
   ],
   "source": [
    "# roll up into a single performance level\n",
    "print(df_joined.shape)\n",
    "grouped_by = ['year', 'district_id', 'district', 'school_id', 'school', 'subject', 'grade', 'group_state', 'proficient_tf']\n",
    "df_joined = df_joined.groupby(grouped_by, as_index=False).agg({'num_tested': 'sum', 'num_at_level': 'sum'})\n",
    "print(df_joined.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2736294, 9)\n",
      "(2736294, 9)\n",
      "(2736294, 10)\n"
     ]
    }
   ],
   "source": [
    "# create 'All' grade rollup\n",
    "grouped_by = ['year', 'district_id', 'district', 'school_id', 'school', 'subject', 'group_state', 'proficient_tf']\n",
    "df_allgrades = df_joined.groupby(grouped_by, as_index=False)['num_at_level'].sum()\n",
    "print(df_allgrades.shape)\n",
    "df_allgrades2 = df_joined.groupby(grouped_by, as_index=False)['num_tested'].sum()\n",
    "print(df_allgrades2.shape)\n",
    "df_allgrades = df_allgrades.merge(df_allgrades2, on=grouped_by)\n",
    "print(df_allgrades.shape)\n",
    "del df_allgrades2\n",
    "df_allgrades['grade'] = 'All Grades'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5294671, 11)\n",
      "(8030965, 11)\n"
     ]
    }
   ],
   "source": [
    "# append 'All' grade rollup to df\n",
    "print(df_joined.shape)\n",
    "df_joined = df_joined.append(df_allgrades, ignore_index=True, sort=True)\n",
    "print(df_joined.shape)\n",
    "del df_allgrades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pct_at_level\n",
    "df_joined['pct_at_level'] = df_joined['num_at_level'] / df_joined['num_tested']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "district          object\n",
      "district_id        int64\n",
      "grade             object\n",
      "group_state       object\n",
      "num_at_level     float64\n",
      "num_tested       float64\n",
      "proficient_tf      int64\n",
      "school            object\n",
      "school_id          int64\n",
      "subject           object\n",
      "year              object\n",
      "pct_at_level     float64\n",
      "dtype: object\n",
      "district          object\n",
      "district_id       object\n",
      "grade             object\n",
      "group_state       object\n",
      "num_at_level     float64\n",
      "num_tested       float64\n",
      "proficient_tf       bool\n",
      "school            object\n",
      "school_id         object\n",
      "subject           object\n",
      "year              object\n",
      "pct_at_level     float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_joined.dtypes)\n",
    "df_joined['district_id'] = df_joined['district_id'].astype(str)\n",
    "df_joined['school_id'] = df_joined['school_id'].astype(str)\n",
    "df_joined['proficient_tf'] = df_joined['proficient_tf'].astype(bool)\n",
    "print(df_joined.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          2013\n",
      "698827     2014\n",
      "1563004    2015\n",
      "2132919    2016\n",
      "3013723    2017\n",
      "3589232    2018\n",
      "4191776    2019\n",
      "Name: year, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_joined['year'].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export data\n",
    "df_joined.to_csv('./data/finalized/tx_proficiency.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
