{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import util\n",
    "\n",
    "proficiency_path = './data/tx/proficiency/'\n",
    "\n",
    "# import column maps\n",
    "map_files = [\n",
    "#     '2019_CAMPSTAAR1_map.csv'\n",
    "#     , '2019_CAMPSTAAR2_map.csv'\n",
    "#     , '2019_CAMPSTAAR4_map.csv'\n",
    "#     , '2019_CAMPSTAAR5_map.csv'\n",
    "#     , '2018_CAMPSTAAR1_map.csv'\n",
    "#     , '2018_CAMPSTAAR2_map.csv'\n",
    "#     , '2018_CAMPSTAAR4_map.csv'\n",
    "#     , '2018_CAMPSTAAR5_map.csv'\n",
    "#     , '2017_CAMPSTAAR1_map.csv'\n",
    "#     , '2017_CAMPSTAAR2_map.csv'\n",
    "#     , '2017_CAMPSTAAR4_map.csv'\n",
    "#     , '2017_CAMPSTAAR5_map.csv'\n",
    "#     , '2016_CAMPSTAAR1_map.csv'\n",
    "#     , '2016_CAMPSTAAR4_map.csv'\n",
    "#     , '2015_CAMPSTAAR1_map.csv'\n",
    "#     , '2015_CAMPSTAAR4_map.csv'\n",
    "    '2014_CAMPSTAAR1_map.csv'\n",
    "    , '2014_CAMPSTAAR4_map.csv'\n",
    "#     , '2013_CAMPSTAAR1_map.csv'\n",
    "#     , '2013_CAMPSTAAR4_map.csv'\n",
    "]\n",
    "\n",
    "years = [x[:4] for x in map_files]\n",
    "filenames = [x[5:15] for x in map_files]\n",
    "\n",
    "df_map = pd.read_csv(proficiency_path + map_files[0])\n",
    "df_map['year'] = df_map.apply(lambda x: years[0], axis = 1)\n",
    "df_map['file'] = df_map.apply(lambda x: filenames[0], axis = 1)\n",
    "\n",
    "for i in range(1, len(map_files)):\n",
    "    temp = pd.read_csv(proficiency_path + map_files[i])\n",
    "    temp['year'] = temp.apply(lambda x: years[i], axis = 1)\n",
    "    temp['file'] = temp.apply(lambda x: filenames[i], axis = 1)\n",
    "    df_map = df_map.append(temp, ignore_index = True, sort = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import proficiency files\n",
    "proficiency_files = [\n",
    "#     '2019_CAMPSTAAR1.txt'\n",
    "#     , '2019_CAMPSTAAR2.txt'\n",
    "#     , '2019_CAMPSTAAR4.txt'\n",
    "#     , '2019_CAMPSTAAR5.txt'\n",
    "#     , '2018_CAMPSTAAR1.txt'\n",
    "#     , '2018_CAMPSTAAR2.txt'\n",
    "#     , '2018_CAMPSTAAR4.txt'\n",
    "#     , '2018_CAMPSTAAR5.txt'\n",
    "#     , '2017_CAMPSTAAR1.txt'\n",
    "#     , '2017_CAMPSTAAR2.txt'\n",
    "#     , '2017_CAMPSTAAR4.txt'\n",
    "#     , '2017_CAMPSTAAR5.txt'\n",
    "#     , '2016_CAMPSTAAR1.txt'\n",
    "#     , '2016_CAMPSTAAR4.txt'\n",
    "#     , '2015_CAMPSTAAR1.txt'\n",
    "#     , '2015_CAMPSTAAR4.txt'\n",
    "    '2014_CAMPSTAAR1.txt'\n",
    "    , '2014_CAMPSTAAR4.txt'\n",
    "#     , '2013_CAMPSTAAR1.txt'\n",
    "#     , '2013_CAMPSTAAR4.txt'\n",
    "]\n",
    "\n",
    "years = [x[:4] for x in proficiency_files]\n",
    "filenames = [x[5:15] for x in proficiency_files]\n",
    "\n",
    "df = pd.read_csv(proficiency_path + proficiency_files[0])\n",
    "value_vars = list(df.columns)\n",
    "value_vars.remove('CAMPUS')\n",
    "df = pd.melt(df, id_vars = ['CAMPUS'], value_vars = value_vars, var_name='NAME', value_name='VALUE')\n",
    "df = df[df['VALUE'] != '.']\n",
    "df['year'] = df.apply(lambda x: years[0], axis = 1)\n",
    "df['file'] = df.apply(lambda x: filenames[0], axis = 1)\n",
    "\n",
    "for i in range(1, len(proficiency_files)):\n",
    "    temp = pd.read_csv(proficiency_path + proficiency_files[i])\n",
    "    value_vars = list(temp.columns)\n",
    "    value_vars.remove('CAMPUS')\n",
    "    temp = pd.melt(temp, id_vars = ['CAMPUS'], value_vars = value_vars, var_name='NAME', value_name='VALUE')\n",
    "    temp = temp[temp['VALUE'] != '.']\n",
    "    temp['year'] = temp.apply(lambda x: years[i], axis = 1)\n",
    "    temp['file'] = temp.apply(lambda x: filenames[i], axis = 1)\n",
    "    df = df.append(temp, ignore_index = True, sort = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import school info files\n",
    "school_files = [\n",
    "#     '2019_CREF.txt'\n",
    "#     , '2018_CREF.txt'\n",
    "#     , '2017_CREF.txt'\n",
    "#     , '2016_CREF.txt'\n",
    "#     , '2015_CREF.txt'\n",
    "    '2014_CREF.txt'\n",
    "#     , '2013_CREF.txt'\n",
    "]\n",
    "\n",
    "years = [x[:4] for x in school_files]\n",
    "\n",
    "df_school = pd.read_csv(proficiency_path + school_files[0])\n",
    "df_school['year'] = df_school.apply(lambda x: years[0], axis = 1)\n",
    "\n",
    "for i in range(1, len(school_files)):\n",
    "    temp = pd.read_csv(proficiency_path + school_files[i])\n",
    "    temp['year'] = temp.apply(lambda x: years[i], axis = 1)\n",
    "    df_school = df_school.append(temp, ignore_index = True, sort = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6518667, 5)\n",
      "(6518667, 8)\n"
     ]
    }
   ],
   "source": [
    "# join column map to proficiency data, deliberately dropping rows we excluded from the column maps\n",
    "print(df.shape)\n",
    "df = df.merge(df_map, on = ['year', 'file', 'NAME'])\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6518667, 8)\n",
      "(6518667, 8)\n"
     ]
    }
   ],
   "source": [
    "# drop First Administration records\n",
    "print(df.shape)\n",
    "df = df[~df.LABEL.str.contains(\"First Administration\")]\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6518667, 8)\n",
      "(4345778, 8)\n"
     ]
    }
   ],
   "source": [
    "# drop rate rows\n",
    "print(df.shape)\n",
    "df = df[~df.LABEL.str.contains('Rate')]\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4345778, 8)\n",
      "(2300552, 8)\n"
     ]
    }
   ],
   "source": [
    "# remove previous year's records, making exception for 2017 data coming from 2018 file\n",
    "print(df.shape)\n",
    "def filterYears(row):\n",
    "    if row['year'] != '2017' and row['LABEL'].find(str(int(row['year']) - 1)) > 0:\n",
    "        return 1\n",
    "    if row['year'] == '2017' and row['LABEL'].find(str(int(row['year']) + 1)) > 0:\n",
    "        return 1\n",
    "    return 0\n",
    "df['deleteFlag'] = df.apply(lambda x: filterYears(x), axis = 1)\n",
    "df = df[df['deleteFlag'] == 0]\n",
    "del df['deleteFlag']\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                     Grade 3\n",
      "93776                 Grade 4\n",
      "186518                Grade 5\n",
      "2153205               Grade 6\n",
      "2204201               Grade 7\n",
      "2248823               Grade 8\n",
      "3376224     EOC Reading/ELA I\n",
      "3418260    EOC Reading/ELA II\n",
      "3457060         EOC Algebra I\n",
      "3520596        EOC US History\n",
      "3557082           EOC Biology\n",
      "Name: grade, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# parse grade level\n",
    "def parseGrade(row):\n",
    "    eocIndex = row['LABEL'].find('EOC')\n",
    "    if row['LABEL'].upper().find('GRADE 3') > 0:\n",
    "        return 'Grade 3'\n",
    "    if row['LABEL'].upper().find('GRADE 4') > 0:\n",
    "        return 'Grade 4'\n",
    "    if row['LABEL'].upper().find('GRADE 5') > 0:\n",
    "        return 'Grade 5'\n",
    "    if row['LABEL'].upper().find('GRADE 6') > 0:\n",
    "        return 'Grade 6'\n",
    "    if row['LABEL'].upper().find('GRADE 7') > 0:\n",
    "        return 'Grade 7'\n",
    "    if row['LABEL'].upper().find('GRADE 8') > 0:\n",
    "        return 'Grade 8'\n",
    "    if eocIndex > 0:\n",
    "        return row['LABEL'][eocIndex:]\n",
    "    return 'All Grades'\n",
    "\n",
    "df['grade'] = df.apply(lambda x: parseGrade(x), axis = 1)\n",
    "df['grade'] = df['grade'].str.replace(',', '')\n",
    "df['grade'] = df['grade'].str.replace('Denominator', '')\n",
    "df['grade'] = df['grade'].str.replace('Numerator', '')\n",
    "df['grade'] = df['grade'].str.strip()\n",
    "print(df['grade'].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                       All Students\n",
      "8720                African American\n",
      "15380                          White\n",
      "22956                       Hispanic\n",
      "31576                American Indian\n",
      "33392              Two or more races\n",
      "38470                          Asian\n",
      "42458               Pacific Islander\n",
      "43102                         Female\n",
      "51798                           Male\n",
      "60504                    Econ Disadv\n",
      "69192                     Special Ed\n",
      "77520                        At Risk\n",
      "86154                            ELL\n",
      "3856080                      Migrant\n",
      "3857400                  Non-Migrant\n",
      "3866120                     Non-CATE\n",
      "3874840              Non-Econ Disadv\n",
      "3883244               Non-Special Ed\n",
      "3891944                  Non-At Risk\n",
      "3900616                      Non-ELL\n",
      "3909324     First-Year-Monitored-ELL\n",
      "3911878    Second-Year-Monitored-ELL\n",
      "5278473                         CATE\n",
      "5278485                Elective-CATE\n",
      "Name: group_state, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# parse group\n",
    "def parseGroup(row):\n",
    "    if row['LABEL'].upper().find('CONTINUOUS ENROLLEE') > 0:\n",
    "        return 'Continuous Enrollee'\n",
    "    if row['LABEL'].upper().find('MOBILE') > 0:\n",
    "        return 'Mobile'\n",
    "    if row['LABEL'].upper().find('NON-AT RISK') > 0:\n",
    "        return 'Non-At Risk'\n",
    "    if row['LABEL'].upper().find('NON-CATE') > 0:\n",
    "        return 'Non-CATE'\n",
    "    if row['LABEL'].upper().find('NON-ELL') > 0 or row['LABEL'].upper().find('NON-EL') > 0:\n",
    "        return 'Non-ELL'\n",
    "    if row['LABEL'].upper().find('NON-ECON DISADV') > 0:\n",
    "        return 'Non-Econ Disadv'\n",
    "    if row['LABEL'].upper().find('NON-MIGRANT') > 0:\n",
    "        return 'Non-Migrant'\n",
    "    if row['LABEL'].upper().find('NON-SPECIAL ED') > 0:\n",
    "        return 'Non-Special Ed'\n",
    "    if row['LABEL'].upper().find('FIRST-YEAR-MONITORED-ELL') > 0 or row['LABEL'].upper().find('FIRST-YEAR-MONITORED-EL') > 0:\n",
    "        return 'First-Year-Monitored-ELL'\n",
    "    if row['LABEL'].upper().find('SECOND-YEAR-MONITORED-ELL') > 0 or row['LABEL'].upper().find('SECOND-YEAR-MONITORED-EL') > 0:\n",
    "        return 'Second-Year-Monitored-ELL'\n",
    "    if row['LABEL'].upper().find('AFRICAN AMERICAN') > 0:\n",
    "        return 'African American'\n",
    "    if row['LABEL'].upper().find('ALL STUDENTS') > 0:\n",
    "        return 'All Students'\n",
    "    if row['LABEL'].upper().find('AMERICAN INDIAN') > 0:\n",
    "        return 'American Indian'\n",
    "    if row['LABEL'].upper().find('ASIAN') > 0:\n",
    "        return 'Asian'\n",
    "    if row['LABEL'].upper().find('FEMALE') > 0:\n",
    "        return 'Female'\n",
    "    if row['LABEL'].upper().find('MALE') > 0:\n",
    "        return 'Male'\n",
    "    if row['LABEL'].upper().find('AT RISK') > 0:\n",
    "        return 'At Risk'\n",
    "    if row['LABEL'].upper().find('ECON DISADV') > 0:\n",
    "        return 'Econ Disadv'\n",
    "    if row['LABEL'].upper().find('HISPANIC') > 0:\n",
    "        return 'Hispanic'\n",
    "    if row['LABEL'].upper().find('PACIFIC ISLANDER') > 0:\n",
    "        return 'Pacific Islander'\n",
    "    if row['LABEL'].upper().find('SPECIAL ED') > 0:\n",
    "        return 'Special Ed'\n",
    "    if row['LABEL'].upper().find('WHITE') > 0:\n",
    "        return 'White'\n",
    "    if row['LABEL'].upper().find('TWO OR MORE RACES') > 0:\n",
    "        return 'Two or more races'\n",
    "    if row['LABEL'].upper().find('ELECTIVE-CATE') > 0:\n",
    "        return 'Elective-CATE'\n",
    "    if row['LABEL'].upper().find('CATE') > 0:\n",
    "        return 'CATE'\n",
    "    if row['LABEL'].upper().find('MIGRANT') > 0:\n",
    "        return 'Migrant'\n",
    "    if row['LABEL'].upper().find('ELL') > 0 or row['LABEL'].upper().find('EL,') > 0:\n",
    "        return 'ELL'\n",
    "    return row['LABEL']\n",
    "        \n",
    "df['group_state'] = df.apply(lambda x: parseGroup(x), axis = 1)\n",
    "print(df['group_state'].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                     ELA\n",
      "273730               Math\n",
      "640186            Science\n",
      "2521399    Social Studies\n",
      "Name: subject, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# parse subject\n",
    "def parseSubject(row):\n",
    "    if row['LABEL'].upper().find('MATH') > 0 or row['LABEL'].upper().find('ALGEBRA') > 0 or row['LABEL'].upper().find('GEOMETRY') > 0:\n",
    "        return 'Math'\n",
    "    if row['LABEL'].upper().find('READING') > 0 or row['LABEL'].upper().find('ELA') > 0 or row['LABEL'].upper().find('WRITING') > 0 or row['LABEL'].upper().find('ENGLISH') > 0:\n",
    "        return 'ELA'\n",
    "    if row['LABEL'].upper().find('SOCIAL STUDIES') > 0 or row['LABEL'].upper().find('HISTORY') > 0 or row['LABEL'].upper().find('GEOGRAPHY') > 0:\n",
    "        return 'Social Studies'\n",
    "    if row['LABEL'].upper().find('SCIENCE') > 0 or row['LABEL'].upper().find('BIOLOGY') > 0 or row['LABEL'].upper().find('PHYSICS') > 0 or row['LABEL'].upper().find('CHEMISTRY') > 0:\n",
    "        return 'Science'\n",
    "    return row['LABEL']\n",
    "\n",
    "df['subject'] = df.apply(lambda x: parseSubject(x), axis = 1)\n",
    "print(df['subject'].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1150276, 11)\n",
      "(1150276, 11)\n"
     ]
    }
   ],
   "source": [
    "# split dataset into numerator/denominator values\n",
    "df_num = df[df.LABEL.str.contains('Numerator')]\n",
    "print(df_num.shape)\n",
    "df_denom = df[df.LABEL.str.contains('Denominator')]\n",
    "print(df_denom.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4360    Phase-in 1 Level II or above\n",
      "Name: performance_level, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "# parse performance level\n",
    "def parsePerformance(row):\n",
    "    if row['LABEL'].upper().find('APPROACHES GRADE LEVEL') > 0:\n",
    "        return 'Approaches Grade Level'\n",
    "    if row['LABEL'].upper().find('MASTERS GRADE LEVEL') > 0:\n",
    "        return 'Masters Grade Level'\n",
    "    if row['LABEL'].upper().find('MEETS GRADE LEVEL') > 0:\n",
    "        return 'Meets Grade Level'\n",
    "    return 'Phase-in 1 Level II or above'\n",
    "\n",
    "df_num['performance_level'] = df_num.apply(lambda x: parsePerformance(x), axis = 1)\n",
    "print(df_num['performance_level'].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4360    1\n",
      "Name: proficient_tf, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# drop unneeded columns\n",
    "df_num = df_num[['CAMPUS', 'VALUE', 'year', 'grade', 'group_state', 'subject', 'performance_level']]\n",
    "df_num = df_num.rename(columns = {'VALUE': 'num_at_level'})\n",
    "\n",
    "def createProficientTF(row):\n",
    "    if row['performance_level'] == 'Approaches Grade Level':\n",
    "        return 0\n",
    "    if row['performance_level'] == 'Phase-in 1 Level II or above' or row['performance_level'] == 'Masters Grade Level' or row['performance_level'] == 'Meets Grade Level':\n",
    "        return 1\n",
    "df_num['proficient_tf'] = df_num.apply(lambda x: createProficientTF(x), axis = 1)\n",
    "print(df_num['proficient_tf'].drop_duplicates())\n",
    "\n",
    "df_denom = df_denom[['CAMPUS', 'VALUE', 'year', 'grade', 'group_state', 'subject']]\n",
    "df_denom = df_denom.rename(columns = {'VALUE': 'num_tested'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1150276, 8)\n",
      "(1035681, 8)\n"
     ]
    }
   ],
   "source": [
    "# roll up all results by subject/grade/group/year/campus/proficient_tf/performance_level\n",
    "print(df_num.shape)\n",
    "grouped_by = ['year', 'CAMPUS', 'subject', 'grade', 'group_state', 'proficient_tf', 'performance_level']\n",
    "# change suppressed values to 0, so they aren't integers\n",
    "df_num['num_at_level'] = [int(x) if int(x) >= 0 else 0 for x in df_num['num_at_level']]\n",
    "df_num = df_num.groupby(grouped_by, as_index = False)['num_at_level'].sum()\n",
    "print(df_num.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1150276, 6)\n",
      "(1035681, 6)\n"
     ]
    }
   ],
   "source": [
    "print(df_denom.shape)\n",
    "grouped_by.remove('proficient_tf')\n",
    "grouped_by.remove('performance_level')\n",
    "# change suppressed values to 0, so they aren't integers\n",
    "df_denom['num_tested'] = [int(x) if int(x) >= 0 else 0 for x in df_denom['num_tested']]\n",
    "df_denom = df_denom.groupby(grouped_by, as_index = False)['num_tested'].sum()\n",
    "print(df_denom.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1035681, 8)\n",
      "(1035681, 6)\n",
      "   year   CAMPUS subject              grade       group_state  proficient_tf  \\\n",
      "0  2014  1902001     ELA  EOC Reading/ELA I  African American              1   \n",
      "1  2014  1902001     ELA  EOC Reading/ELA I      All Students              1   \n",
      "2  2014  1902001     ELA  EOC Reading/ELA I             Asian              1   \n",
      "3  2014  1902001     ELA  EOC Reading/ELA I           At Risk              1   \n",
      "4  2014  1902001     ELA  EOC Reading/ELA I              CATE              1   \n",
      "\n",
      "              performance_level  num_at_level  num_tested  \n",
      "0  Phase-in 1 Level II or above             5           5  \n",
      "1  Phase-in 1 Level II or above            52          66  \n",
      "2  Phase-in 1 Level II or above             0           0  \n",
      "3  Phase-in 1 Level II or above            32          46  \n",
      "4  Phase-in 1 Level II or above            16          20  \n",
      "(1035681, 9)\n"
     ]
    }
   ],
   "source": [
    "# join num_at_level and num_tested values to each other\n",
    "print(df_num.shape)\n",
    "print(df_denom.shape)\n",
    "df_joined = df_num.merge(df_denom, on = ['CAMPUS', 'year', 'subject', 'grade', 'group_state'], how='inner')\n",
    "print(df_joined.head())\n",
    "print(df_joined.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change suppressed values back to 0\n",
    "def suppressNumAtLevel(row):\n",
    "    if row['num_at_level'] == 0 and row['num_tested'] == 0:\n",
    "        return 'N/A'\n",
    "    return row['num_at_level']\n",
    "\n",
    "def suppressNumTested(row):\n",
    "    if row['num_at_level'] == 0 and row['num_tested'] == 0:\n",
    "        return 'N/A'\n",
    "    return row['num_tested']\n",
    "\n",
    "df_joined['num_at_level'] = df_joined.apply(lambda x: suppressNumAtLevel(x), axis = 1)\n",
    "df_joined['num_tested'] = df_joined.apply(lambda x: suppressNumTested(x), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate pct_at_level\n",
    "def calc_pct_at_level(row):\n",
    "    if row['num_at_level'] == 'N/A' or row['num_tested'] == 'N/A':\n",
    "        return 'N/A'\n",
    "    return float(row['num_at_level']) / float(row['num_tested'])\n",
    "df_joined['pct_at_level'] = df_joined.apply(lambda x: calc_pct_at_level(x), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1035681, 10)\n",
      "(1035681, 13)\n",
      "   year  school_id subject              grade       group_state  \\\n",
      "0  2014    1902001     ELA  EOC Reading/ELA I  African American   \n",
      "1  2014    1902001     ELA  EOC Reading/ELA I      All Students   \n",
      "2  2014    1902001     ELA  EOC Reading/ELA I             Asian   \n",
      "3  2014    1902001     ELA  EOC Reading/ELA I           At Risk   \n",
      "4  2014    1902001     ELA  EOC Reading/ELA I              CATE   \n",
      "\n",
      "   proficient_tf             performance_level num_at_level  num_tested  \\\n",
      "0              1  Phase-in 1 Level II or above            5           5   \n",
      "1              1  Phase-in 1 Level II or above           52          66   \n",
      "2              1  Phase-in 1 Level II or above          N/A           0   \n",
      "3              1  Phase-in 1 Level II or above           32          46   \n",
      "4              1  Phase-in 1 Level II or above           16          20   \n",
      "\n",
      "  pct_at_level      school  district_id    DISTNAME  \n",
      "0            1  CAYUGA H S         1902  CAYUGA ISD  \n",
      "1     0.787879  CAYUGA H S         1902  CAYUGA ISD  \n",
      "2          N/A  CAYUGA H S         1902  CAYUGA ISD  \n",
      "3     0.695652  CAYUGA H S         1902  CAYUGA ISD  \n",
      "4          0.8  CAYUGA H S         1902  CAYUGA ISD  \n"
     ]
    }
   ],
   "source": [
    "# join campus data file\n",
    "print(df_joined.shape)\n",
    "df_school = df_school[['CAMPUS', 'CAMPNAME', 'DISTRICT', 'DISTNAME']]\n",
    "df_joined = df_joined.merge(df_school, on = 'CAMPUS')\n",
    "df_joined = df_joined.rename(columns = {\n",
    "    'CAMPUS': 'school_id',\n",
    "    'CAMPNAME': 'school',\n",
    "    'DISTRICT': 'district_id',\n",
    "    'distname': 'district'\n",
    "})\n",
    "print(df_joined.shape)\n",
    "print(df_joined.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export data\n",
    "# df.to_csv('./data/finalized/tx_proficiency.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
