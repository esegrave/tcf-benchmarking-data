{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import util\n",
    "\n",
    "proficiency_path = './data/tn/proficiency/'\n",
    "\n",
    "proficiency_files = [\n",
    "    'tn_proficiency_2012_cleaned.csv'\n",
    "    , 'tn_proficiency_2013_cleaned.csv'\n",
    "    , 'tn_proficiency_2014_cleaned.csv'\n",
    "    , 'tn_proficiency_2015_cleaned.csv'\n",
    "    , 'tn_proficiency_2016_cleaned.csv'\n",
    "    , 'tn_proficiency_2017_cleaned.csv'\n",
    "    , 'tn_proficiency_2018_cleaned.csv'\n",
    "    , 'tn_proficiency_2019_cleaned.csv'\n",
    "]\n",
    "\n",
    "years = [x[15:19] for x in proficiency_files]\n",
    "\n",
    "df = pd.read_csv(proficiency_path + proficiency_files[0])\n",
    "df['year'] = df.apply(lambda x: years[0], axis=1)\n",
    "\n",
    "for i in range(1, len(proficiency_files)):\n",
    "    temp = pd.read_csv(proficiency_path + proficiency_files[i])\n",
    "    temp['year'] = temp.apply(lambda x: years[i], axis=1)\n",
    "    df = df.append(temp, ignore_index = True, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(440633, 32)\n",
      "(2443008, 32)\n",
      "(766162, 32)\n"
     ]
    }
   ],
   "source": [
    "# get school and district names for 2017 data\n",
    "df_2017 = df[df['year'] == '2017']\n",
    "print(df_2017.shape)\n",
    "df_all = df[df['year'] != '2017']\n",
    "print(df_all.shape)\n",
    "del df_2017['school']\n",
    "del df_2017['district']\n",
    "\n",
    "df_ids = df_all[['district_id', 'district', 'school_id', 'school']].drop_duplicates()\n",
    "df_2017 = pd.merge(df_2017, df_ids, on=['district_id', 'school_id'], how = 'left')\n",
    "print(df_2017.shape)\n",
    "df = df_all.append(df_2017, ignore_index = True, sort = True)\n",
    "del df_2017\n",
    "del df_all\n",
    "del df_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                                 All Groups\n",
      "1                                                      Black\n",
      "2          Economically Disadvantaged (Free or Reduced Pr...\n",
      "3                                 Students with Disabilities\n",
      "4                                                      White\n",
      "24                                                     Asian\n",
      "34                                                  Hispanic\n",
      "453                                          Native American\n",
      "1367                                          Hawaiian or PI\n",
      "162781                          Hawaiian or Pacific Islander\n",
      "162782                            Economically Disadvantaged\n",
      "162784                             English Language Learners\n",
      "162785                  English Language Learners with T1/T2\n",
      "162786                        Black/Hispanic/Native American\n",
      "582903                        Non-Economically Disadvantaged\n",
      "582904                        Non-Students with Disabilities\n",
      "582905                         Non-English Language Learners\n",
      "582906                Non-English Language Learners/T1 or T2\n",
      "1389397                   Non-Black/Hispanic/Native American\n",
      "1389399                Non-English Learners/Transitional 1-4\n",
      "1389402                                       Super Subgroup\n",
      "1389405                     American Indian or Alaska Native\n",
      "1389407                            Black or African American\n",
      "1389410                     English Learner Transitional 1-4\n",
      "1389411                                     English Learners\n",
      "1389412               English Learners with Transitional 1-4\n",
      "1390621            Native Hawaiian or Other Pacific Islander\n",
      "1984568                                               Female\n",
      "1984569                                                 Male\n",
      "1984597                                               Gifted\n",
      "2085467                                              Migrant\n",
      "2443012                                 Non-English Learners\n",
      "2443013                        Non-English Learners/T1 or T2\n",
      "2444062                          English Learners with T1/T2\n",
      "Name: group_state, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# rename aggregate group names\n",
    "df['group_state'] = [x if x != 'All' else 'All Groups' for x in df['group_state']]\n",
    "df['group_state'] = [x if x != 'All Students' else 'All Groups' for x in df['group_state']]\n",
    "print(df['group_state'].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create subject map\n",
    "# subject_map = [['Algebra I', 'Math']\n",
    "#                , ['Algebra II', 'Math']\n",
    "#                , ['Biology I', 'Science']\n",
    "#                , ['English I', 'ELA']\n",
    "#                , ['English II', 'ELA']\n",
    "#                , ['English III', 'ELA']\n",
    "#                , ['Math', 'Math']\n",
    "#                , ['Reading/Language', 'ELA']\n",
    "#                , ['Science', 'Science']\n",
    "#                , ['US History', 'US History']\n",
    "#                , ['RLA', 'ELA']\n",
    "#                , ['Social Studies', 'Social Studies']\n",
    "#                , ['Chemistry', 'Science']\n",
    "#                , ['Integrated Math I', 'Math']\n",
    "#                , ['Integrated Math II', 'Math']\n",
    "#                , ['Geometry', 'Math']\n",
    "#                , ['Integrated Math III', 'Math']\n",
    "#                , ['ELA', 'ELA']\n",
    "#               ]\n",
    "# df_subjects = pd.DataFrame(subject_map, columns = ['subject', 'subject_cleaned']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join subject map to assessment data\n",
    "# df = pd.merge(df, df_subjects, on='subject')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete uncleaned subject field and rename new\n",
    "# del df['subject']\n",
    "# df = df.rename(columns={\"subject_cleaned\": \"subject\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Number Advanced', 'Number Approaching', 'Number Basic', 'Number Below',\n",
      "       'Number Below Basic', 'Number Enrolled', 'Number Mastered',\n",
      "       'Number On Track', 'Number Proficient', 'Percent Advanced',\n",
      "       'Percent Approaching', 'Percent Basic', 'Percent Below',\n",
      "       'Percent Below Basic', 'Percent Below Basic or Basic',\n",
      "       'Percent Mastered', 'Percent On Track', 'Percent On Track or Mastered',\n",
      "       'Percent Proficient', 'Percent Proficient or Advanced', 'district',\n",
      "       'district_id', 'enrolled', 'grade', 'group_state', 'num_tested',\n",
      "       'school', 'school_id', 'subject', 'test', 'tested', 'year'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_vars = ['year', 'district_id', 'district', 'school_id', 'school', 'grade', 'group_state', 'subject', 'num_tested']\n",
    "# reshape scores\n",
    "df = pd.melt(df, id_vars=id_vars\n",
    "        , value_vars=[\n",
    "            'Number Advanced'\n",
    "            , 'Number Mastered'\n",
    "            , 'Number On Track'\n",
    "            , 'Number Proficient'],\n",
    "        var_name='performance_level'\n",
    "        , value_name='num_at_level')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create proficient_tf\n",
    "df['proficient_tf'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert num_at_level and num_tested to float\n",
    "def toFloat(row, column):\n",
    "    try:\n",
    "        return float(row[column])\n",
    "    except:\n",
    "        return np.nan\n",
    "df['num_at_level'] = df.apply(lambda x: toFloat(x, 'num_at_level'), axis = 1)\n",
    "df['num_tested'] = df.apply(lambda x: toFloat(x, 'num_tested'), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12836680, 12)\n",
      "(1784074, 12)\n"
     ]
    }
   ],
   "source": [
    "# remove rows with no scores\n",
    "print(df.shape)\n",
    "df = df.dropna(subset=['num_tested', 'num_at_level'])\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1784074, 12)\n",
      "(891225, 11)\n"
     ]
    }
   ],
   "source": [
    "# roll up into a single performance level\n",
    "print(df.shape)\n",
    "grouped_by = ['year', 'district_id', 'district', 'school_id', 'school', 'subject', 'grade', 'group_state', 'proficient_tf']\n",
    "df = df.groupby(grouped_by, as_index=False).agg({'num_tested': 'sum', 'num_at_level': 'sum'})\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pct_at_level\n",
    "df['pct_at_level'] = df['num_at_level'] / df['num_tested']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year              object\n",
      "district_id        int64\n",
      "district          object\n",
      "school_id          int64\n",
      "school            object\n",
      "subject           object\n",
      "grade             object\n",
      "group_state       object\n",
      "proficient_tf      int64\n",
      "num_tested       float64\n",
      "num_at_level     float64\n",
      "pct_at_level     float64\n",
      "dtype: object\n",
      "year              object\n",
      "district_id       object\n",
      "district          object\n",
      "school_id         object\n",
      "school            object\n",
      "subject           object\n",
      "grade             object\n",
      "group_state       object\n",
      "proficient_tf       bool\n",
      "num_tested       float64\n",
      "num_at_level     float64\n",
      "pct_at_level     float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)\n",
    "df['district_id'] = df['district_id'].astype(str)\n",
    "df['school_id'] = df['school_id'].astype(str)\n",
    "df['proficient_tf'] = df['proficient_tf'].astype(bool)\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as cleaned proficiency\n",
    "df.to_csv('./data/finalized/tn_proficiency.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
