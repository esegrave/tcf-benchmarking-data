{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize state list\n",
    "states = [\n",
    "    'ca',\n",
    "#     'co',\n",
    "    'dc',\n",
    "#     'ks',\n",
    "    'ga',\n",
    "    'la',\n",
    "    'ma',\n",
    "    'mn',\n",
    "    'mo',\n",
    "    'nj',\n",
    "    'pa',\n",
    "#     'tn',\n",
    "    'tx'\n",
    "]\n",
    "\n",
    "states=['ca']\n",
    "\n",
    "finalized_path = './data/finalized/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanStrings(row, column):\n",
    "    try:\n",
    "        return str(int(float(row[column])))\n",
    "    except:\n",
    "        return row[column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28840, 6)\n",
      "  district_id school_id in_city charter state  flag\n",
      "0         NaN       NaN     NaN     NaN    la     1\n",
      "1           1         1     NaN     NaN    ma     1\n",
      "2           1         1     NaN     NaN    mn     1\n",
      "3           1        15     NaN     NaN    ma     1\n",
      "4           1         2     NaN     NaN    mn     1\n"
     ]
    }
   ],
   "source": [
    "# import in_city & charter from directory\n",
    "df_directory = pd.read_csv(finalized_path + 'directory_data_combined.csv',dtype={'district_id':str,'school_id':str,'district':str,'school':str,'in_city':str,'charter':str,'state':str})\n",
    "df_directory['state'] = df_directory['state'].str.lower()\n",
    "df_directory['flag'] = 1\n",
    "df_directory = df_directory[['district_id', 'school_id', 'in_city', 'charter', 'state', 'flag']]\n",
    "# apply cleanStrings function to district_id and school_id\n",
    "df_directory['district_id'] = df_directory.apply(lambda x: cleanStrings(x, 'district_id') ,axis=1)\n",
    "df_directory['school_id'] = df_directory.apply(lambda x: cleanStrings(x, 'school_id') ,axis=1)\n",
    "\n",
    "print(df_directory.shape)\n",
    "print(df_directory.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1384, 37)\n",
      "    grantmerge state educationchampion grantid    grantscope district_id  \\\n",
      "0  matched (3)    ca        Educate 78   11101  School-based       61259   \n",
      "1  matched (3)    ca        Educate 78   11201  School-based       61259   \n",
      "2  matched (3)    ca        Educate 78   11301  School-based       61259   \n",
      "3  matched (3)    ca        Educate 78   11301  School-based       61259   \n",
      "4  matched (3)    ca        Educate 78   11301  School-based       61259   \n",
      "\n",
      "                        stateleaname previousstateleaid schoolgranteeid  \\\n",
      "0  Santa Fe Community School- CLOSED                NaN            1191   \n",
      "1  Santa Fe Community School- CLOSED                NaN            1192   \n",
      "2                    Amethod Schools                NaN            1195   \n",
      "3                    Amethod Schools                NaN            1194   \n",
      "4                    Amethod Schools                NaN            1196   \n",
      "\n",
      "  school_id  ... totalamountdisbursed otherfundscontributed notes schooltype  \\\n",
      "0   6002166  ...                844.0               Unknown   NaN        New   \n",
      "1   6002166  ...              12000.0               Unknown   NaN        New   \n",
      "2   6111660  ...              25000.0               Unknown   NaN   Existing   \n",
      "3    129635  ...              25000.0               Unknown   NaN   Existing   \n",
      "4    114868  ...              25000.0               Unknown   NaN   Existing   \n",
      "\n",
      "                               schoolgrantstrategy endofgrantenrollmentgoal  \\\n",
      "0             New Start (new school, new operator)                      NaN   \n",
      "1             New Start (new school, new operator)                      NaN   \n",
      "2  Improvement (existing school, current operator)                      NaN   \n",
      "3  Improvement (existing school, current operator)                      NaN   \n",
      "4  Improvement (existing school, current operator)                      NaN   \n",
      "\n",
      "  wasanyportionofthetotalgra portionedamountcommitted  \\\n",
      "0                        Yes                   844.00   \n",
      "1                        Yes                 12000.00   \n",
      "2                         No                  8333.33   \n",
      "3                         No                  8333.33   \n",
      "4                         No                  8333.33   \n",
      "\n",
      "  portionedamountdisbursed no_id_status  \n",
      "0                   844.00          NaN  \n",
      "1                 12000.00          NaN  \n",
      "2                  8333.33          NaN  \n",
      "3                  8333.33          NaN  \n",
      "4                  8333.33          NaN  \n",
      "\n",
      "[5 rows x 37 columns]\n"
     ]
    }
   ],
   "source": [
    "# import grant data\n",
    "df_grant = pd.read_csv(finalized_path + 'grants_clean_unifiedForAnalysis.csv',dtype={'grantmerge': str,'state':str,'educationchampion':str,'grantid':str,'grantscope':str,'district_id':str,'stateleaname':str,'previousstateleaid':str,'schoolgranteeid':str,'school_id':str,'stateschoolname':str,'previousstateschoolid':str,'granteeisthesameasgrantben':str,'granteenameifdifferentfrom':str,'leagrantstrategy':str,'strategyenrollmentmax':str,'strategyqualityimprovement':str,'strategyexpansion':str,'strategynewstart':str,'endofgrantleaenrollmentgoal':str,'granttype':str,'supportorganizationsinvolved':str,'levelofedchampinvolvement':str,'duration':str,'startdate':str,'enddate':str,'totalamountcommitted':np.float64,'totalamountdisbursed':np.float64,'otherfundscontributed':str,'notes':str,'schooltype':str,'schoolgrantstrategy':str,'endofgrantenrollmentgoal':np.float64,'wasanyportionofthetotalgra':str,'portionedamountcommitted':np.float64,'portionedamountdisbursed':np.float64,'no_id_status':str})\n",
    "\n",
    "# apply cleanStrings function to district_id and school_id\n",
    "df_grant['district_id'] = df_grant.apply(lambda x: cleanStrings(x, 'district_id') ,axis=1)\n",
    "df_grant['school_id'] = df_grant.apply(lambda x: cleanStrings(x, 'school_id') ,axis=1)\n",
    "grants_district = df_grant[df_grant.grantscope.eq('LEA-wide')]\n",
    "grants_school = df_grant[df_grant.grantscope.eq('School-based')]\n",
    "\n",
    "print(df_grant.shape)\n",
    "print(df_grant.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 8)\n",
      "  edchamp_id                      edchamp_name         city state   latitude  \\\n",
      "0          1               Boston Schools Fund       Boston    ma  42.370567   \n",
      "1          2           City Education Partners  San Antonio    tx  29.468413   \n",
      "2          3                      EdForward DC   Washington    dc  38.911936   \n",
      "3          4                        Educate 78      Oakland    ca  37.786027   \n",
      "4          5  New Jersey Children's Foundation       Newark    nj  40.736101   \n",
      "\n",
      "    longitude first_grant_start launch_year_spring  \n",
      "0  -71.026964           9/24/15               2016  \n",
      "1  -98.528889            9/1/15               2016  \n",
      "2  -77.016719           9/15/16               2017  \n",
      "3 -122.223779          12/12/13               2014  \n",
      "4  -74.225090            7/1/19               2020  \n"
     ]
    }
   ],
   "source": [
    "# import ed champion\n",
    "df_champ = pd.read_csv(finalized_path + 'ed_champions_data.csv', dtype={'edchamp_id':str,'edchamp_name':str,'city':str,'state':str,'latitude':np.float64,'longitude':np.float64,'first_grant_start':str,'launch_year_spring':str})\n",
    "df_champ['state'] = df_champ['state'].str.lower()\n",
    "\n",
    "print(df_champ.shape)\n",
    "print(df_champ.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(301, 4)\n",
      "  state grade grade_new        file\n",
      "0    ca     1         1  enrollment\n",
      "1    ca     2         2  enrollment\n",
      "2    ca     9    HS/EOC  enrollment\n",
      "3    ca    10    HS/EOC  enrollment\n",
      "4    ca    12    HS/EOC  enrollment\n"
     ]
    }
   ],
   "source": [
    "# import grade map\n",
    "df_grademap = pd.read_csv(finalized_path + 'grade_lookup.csv',dtype={'state':str,'grade':str,'grade_new':str, 'file':str})\n",
    "\n",
    "print(df_grademap.shape)\n",
    "print(df_grademap.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(167, 4)\n",
      "  state       group_state     group_new        file\n",
      "0    ca  African American         Black  enrollment\n",
      "1    ca          Hispanic      Hispanic  enrollment\n",
      "2    ca             White         White  enrollment\n",
      "3    ca           frplk12    Low-Income  enrollment\n",
      "4    ca          totalk12  All Students  enrollment\n"
     ]
    }
   ],
   "source": [
    "# import group map\n",
    "df_groupmap = pd.read_csv(finalized_path + 'group_lookup.csv',dtype={'state':str,'group_state':str,'group_new':str, 'file':str})\n",
    "\n",
    "print(df_groupmap.shape)\n",
    "print(df_groupmap.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84, 4)\n",
      "  state subject subject_new         file\n",
      "0    ca     ELA         ELA  proficiency\n",
      "1    ca    Math        Math  proficiency\n",
      "2    co     ELA         ELA  proficiency\n",
      "3    co    Math        Math  proficiency\n",
      "4    dc     ELA         ELA  proficiency\n"
     ]
    }
   ],
   "source": [
    "# import subject map\n",
    "df_subjectmap = pd.read_csv(finalized_path + 'subject_lookup.csv',dtype={'state':str,'subject':str,'subject_new':str, 'file':str})\n",
    "\n",
    "print(df_subjectmap.shape)\n",
    "print(df_subjectmap.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing ca\n",
      "Pre city map\n",
      "(2235695, 9)\n",
      "Post city map\n",
      "(2235695, 11)\n",
      "After all appends\n",
      "(2235695, 11)\n",
      "After grade/group map\n",
      "(817146, 11)\n",
      "After grant join\n",
      "(1252700, 80)\n",
      "After ed champ map\n",
      "(1252700, 87)\n",
      "0    ca\n",
      "Name: state, dtype: object\n",
      "   year state district_id                            district school_id  \\\n",
      "0  2015    ca       10017  Alameda County Office of Education    109835   \n",
      "1  2015    ca       10017  Alameda County Office of Education    109835   \n",
      "2  2015    ca       10017  Alameda County Office of Education    109835   \n",
      "3  2015    ca       10017  Alameda County Office of Education    109835   \n",
      "4  2015    ca       10017  Alameda County Office of Education    109835   \n",
      "\n",
      "                school grade     group in_city charter  ...  \\\n",
      "0  FAME Public Charter     1     Black       0       1  ...   \n",
      "1  FAME Public Charter     1  Hispanic       0       1  ...   \n",
      "2  FAME Public Charter     1     White       0       1  ...   \n",
      "3  FAME Public Charter     2     Black       0       1  ...   \n",
      "4  FAME Public Charter     2  Hispanic       0       1  ...   \n",
      "\n",
      "   portionedamountcommitted_grant_school  \\\n",
      "0                                    NaN   \n",
      "1                                    NaN   \n",
      "2                                    NaN   \n",
      "3                                    NaN   \n",
      "4                                    NaN   \n",
      "\n",
      "  portionedamountdisbursed_grant_school no_id_status_grant_school edchamp_id  \\\n",
      "0                                   NaN                       NaN          4   \n",
      "1                                   NaN                       NaN          4   \n",
      "2                                   NaN                       NaN          4   \n",
      "3                                   NaN                       NaN          4   \n",
      "4                                   NaN                       NaN          4   \n",
      "\n",
      "  edchamp_name     city   latitude   longitude first_grant_start  \\\n",
      "0   Educate 78  Oakland  37.786027 -122.223779          12/12/13   \n",
      "1   Educate 78  Oakland  37.786027 -122.223779          12/12/13   \n",
      "2   Educate 78  Oakland  37.786027 -122.223779          12/12/13   \n",
      "3   Educate 78  Oakland  37.786027 -122.223779          12/12/13   \n",
      "4   Educate 78  Oakland  37.786027 -122.223779          12/12/13   \n",
      "\n",
      "  launch_year_spring  \n",
      "0               2014  \n",
      "1               2014  \n",
      "2               2014  \n",
      "3               2014  \n",
      "4               2014  \n",
      "\n",
      "[5 rows x 87 columns]\n",
      "(1252700, 87)\n"
     ]
    }
   ],
   "source": [
    "# import enrollment files\n",
    "df_e = pd.DataFrame()\n",
    "\n",
    "for state in states:\n",
    "    try:\n",
    "        temp = pd.read_csv(finalized_path + state + '_enrollment.csv',dtype={'year': str,'district_id': str,'district': str,'school_id': str,'school': str,'grade': str,'group_state': str,'num': np.int64})\n",
    "    except: \n",
    "        print('No enrollment file for ' + state)\n",
    "        continue\n",
    "    temp['state'] = state\n",
    "    print('Importing ' + state)\n",
    "    # apply cleanStrings function to district_id and school_id\n",
    "    temp['district_id'] = temp.apply(lambda x: cleanStrings(x, 'district_id') ,axis=1)\n",
    "    temp['school_id'] = temp.apply(lambda x: cleanStrings(x, 'school_id') ,axis=1)\n",
    "    \n",
    "    print('Pre city map')\n",
    "    print(temp.shape)\n",
    "    # join city file\n",
    "    if state == 'tx':\n",
    "        temp_dir = df_directory[['state', 'district_id', 'in_city', 'charter', 'flag']].drop_duplicates()\n",
    "        temp = temp.merge(temp_dir, on=['state', 'district_id'], how = 'left')\n",
    "        del temp_dir\n",
    "    else:\n",
    "        temp = temp.merge(df_directory, on=['state', 'district_id', 'school_id'], how = 'left')\n",
    "        temp['flag'] = temp.apply(lambda x: '1' if x['state'] == 'dc' and str(x['district_id']).strip() == '1' else x['flag'], axis = 1)\n",
    "        temp['in_city'] = temp.apply(lambda x: '1' if x['state'] == 'dc' and str(x['district_id']).strip() == '1' else x['in_city'], axis = 1)\n",
    "    del temp['flag']\n",
    "    print('Post city map')\n",
    "    print(temp.shape)\n",
    "    temp['charter'] = temp['charter'].fillna('0')\n",
    "    temp['in_city'] = temp['in_city'].fillna('0')\n",
    "    \n",
    "    df_e = df_e.append(temp, ignore_index = True, sort = True)\n",
    "\n",
    "print('After all appends')\n",
    "print(df_e.shape)\n",
    "# join groupmap and grademap\n",
    "df_e = df_e.merge(df_grademap, on=['state','grade'], how='left')\n",
    "df_e = df_e.merge(df_groupmap, on=['state','group_state'], how='left')\n",
    "df_e[df_e.grade_new.isnull()][['state', 'grade']].drop_duplicates().to_csv('unmatched_grade_enrollment.csv')\n",
    "df_e[df_e.group_new.isnull()][['state', 'group_state']].drop_duplicates().to_csv('unmatched_group_enrollment.csv')\n",
    "df_e = df_e.groupby(['year', 'state', 'district_id', 'district', 'school_id', 'school', 'grade_new', 'group_new', 'in_city', 'charter'], as_index=False)['num'].sum()\n",
    "df_e = df_e.rename(columns={'grade_new': 'grade', 'group_new': 'group'})\n",
    "print('After grade/group map')\n",
    "print(df_e.shape)\n",
    "# join grants data to enrollment data\n",
    "df_e = df_e.merge(grants_district, on=['state', 'district_id'], suffixes=('', '_grant_district'), how='left')\n",
    "df_e = df_e.merge(grants_school, on=['state', 'district_id', 'school_id'], suffixes=('', '_grant_school'), how='left')\n",
    "print('After grant join')\n",
    "print(df_e.shape)\n",
    "\n",
    "# join ed champion\n",
    "df_e = df_e.merge(df_champ, on='state', how='left')\n",
    "print('After ed champ map')\n",
    "print(df_e.shape)\n",
    "\n",
    "print(df_e['state'].drop_duplicates())\n",
    "print(df_e.head(5))\n",
    "print(df_e.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ca\n",
      "(709291, 14)\n",
      "After grade lookups\n",
      "(709291, 16)\n",
      "After group lookups\n",
      "(709291, 18)\n",
      "After subject lookups\n",
      "(709291, 20)\n",
      "After roll up\n",
      "(709291, 10)\n",
      "after composite\n",
      "(1069045, 10)\n",
      "after city file\n",
      "(1069045, 12)\n",
      "after state z\n",
      "(1069045, 16)\n",
      "after city z\n",
      "(1069045, 20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:172: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:173: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:174: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:176: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:177: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:178: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:180: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:181: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:183: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:184: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    ca\n",
      "Name: state, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# import proficiency files\n",
    "df_p = pd.DataFrame()\n",
    "df_unjoined_cities = pd.DataFrame()\n",
    "\n",
    "for state in states:\n",
    "    print('Processing ' + state)\n",
    "    try:\n",
    "        temp = pd.read_csv(finalized_path + state + '_proficiency.csv',dtype={'year': str,'district_id': str,'district': str,'school_id': str,'school': str,'grade': str,'group_state': str,'subject': str,'proficient_tf': bool,'num_at_level': np.float64,'num_tested': np.float64,'pct_at_level': np.float64})\n",
    "    except:\n",
    "        print('No proficiency file for ' + state)\n",
    "        continue\n",
    "    # apply cleanStrings function to district_id and school_id\n",
    "    temp['district_id'] = temp.apply(lambda x: cleanStrings(x, 'district_id') ,axis=1)\n",
    "    temp['school_id'] = temp.apply(lambda x: cleanStrings(x, 'school_id') ,axis=1)\n",
    "    temp['state'] = state\n",
    "\n",
    "    # merge subject_map, group_map, and grade_map\n",
    "    print(temp.shape)\n",
    "    temp = temp.merge(df_grademap, on=['state','grade'], how='left')\n",
    "    temp[temp.grade_new.isnull()][['state', 'grade']].drop_duplicates().to_csv('unmatched_grade_proficiency.csv')\n",
    "    temp = temp[~temp.grade_new.isnull()]\n",
    "    print('After grade lookups')\n",
    "    print(temp.shape)\n",
    "    temp = temp.merge(df_groupmap, on=['state','group_state'], how='left')\n",
    "    temp[temp.group_new.isnull()][['state', 'group_state']].drop_duplicates().to_csv('unmatched_group_proficiency.csv')\n",
    "    temp = temp[~temp.group_new.isnull()]\n",
    "    print('After group lookups')\n",
    "    print(temp.shape)\n",
    "    temp = temp.merge(df_subjectmap, on=['state','subject'], how='left')\n",
    "    temp[temp.subject_new.isnull()][['state', 'subject']].drop_duplicates().to_csv('unmatched_subject_proficiency.csv')\n",
    "    temp = temp[~temp.subject_new.isnull()]\n",
    "    print('After subject lookups')\n",
    "    print(temp.shape)\n",
    "    \n",
    "    # roll up results by averaged pct_at_level\n",
    "    temp = temp.groupby(['year', 'state', 'district_id', 'district', 'school_id', 'school', 'grade_new', 'group_new', 'subject_new'], as_index=False)['pct_at_level'].mean()\n",
    "    temp = temp.rename(columns={'grade_new': 'grade', 'group_new': 'group', 'subject_new':'subject'})\n",
    "    print('After roll up')\n",
    "    print(temp.shape)\n",
    "    \n",
    "    # create composite subject by averaging pct_at_level as a simple average of cleaned ELA/Math subjects\n",
    "    temp_comp = temp[temp.subject.isin(['ELA','Math'])]\n",
    "    temp_comp = temp_comp.groupby(['year','state', 'district_id', 'district', 'school_id', 'school', 'grade', 'group'], as_index=False)['pct_at_level'].mean()\n",
    "    temp_comp['subject'] = 'Composite'\n",
    "    temp = temp.append(temp_comp, ignore_index = True)\n",
    "    del temp_comp\n",
    "    print('after composite')\n",
    "    print(temp.shape)\n",
    "    \n",
    "    # join city file\n",
    "    if state == 'tx':\n",
    "        temp_dir = df_directory[['state', 'district_id', 'in_city', 'charter', 'flag']].drop_duplicates()\n",
    "        temp = temp.merge(temp_dir, on=['state', 'district_id'], how = 'left')\n",
    "        del temp_dir\n",
    "    else:\n",
    "        temp = temp.merge(df_directory, on=['state', 'district_id', 'school_id'], how = 'left')\n",
    "        temp['flag'] = temp.apply(lambda x: 1 if x['state'] == 'dc' and x['district_id'].strip() == '1' else x['flag'], axis = 1)\n",
    "        temp['in_city'] = temp.apply(lambda x: 1 if x['state'] == 'dc' and x['district_id'].strip() == '1' else x['in_city'], axis = 1)\n",
    "    # append unjoined records to df_unjoined_cities for Steve\n",
    "    temp[temp.flag != 1].to_csv('unjoined_city_flag.csv')\n",
    "    del temp['flag']\n",
    "    temp['charter'] = temp['charter'].fillna('0')\n",
    "    temp['in_city'] = temp['in_city'].fillna('0')\n",
    "    print('after city file')\n",
    "    print(temp.shape)\n",
    "    # create state average & state std dev\n",
    "    temp_avg = temp.groupby(['year', 'grade', 'subject', 'group'], as_index = False)['pct_at_level'].mean()\n",
    "    temp_dev = temp.groupby(['year', 'grade', 'subject', 'group'])['pct_at_level'].std()\n",
    "    # merge state average & std dev\n",
    "    temp = temp.merge(temp_avg, on=['year', 'grade', 'subject', 'group'])\n",
    "    temp = temp.merge(temp_dev, on=['year', 'grade', 'subject', 'group'])\n",
    "    temp = temp.rename(columns={'pct_at_level': 'st_std', 'pct_at_level_y': 'st_avg', 'pct_at_level_x': 'pct_at_level'})\n",
    "    del temp_avg\n",
    "    del temp_dev\n",
    "    # create state z score\n",
    "    temp['st_z'] = (temp['pct_at_level'] - temp['st_avg']) / temp['st_std']\n",
    "    temp['above_st_avg'] = temp['pct_at_level'] > temp['st_avg']\n",
    "    print('after state z')\n",
    "    print(temp.shape)\n",
    "\n",
    "    # create city average\n",
    "    temp_avg = temp.groupby(['year', 'grade', 'subject', 'group', 'in_city'], as_index = False)['pct_at_level'].mean()\n",
    "    # create city std dev\n",
    "    temp_dev = temp.groupby(['year', 'grade', 'subject', 'group', 'in_city'])['pct_at_level'].std()\n",
    "    # merge city average & std dev\n",
    "    temp = temp.merge(temp_avg, on=['year', 'grade', 'subject', 'group', 'in_city'])\n",
    "    temp = temp.merge(temp_dev, on=['year', 'grade', 'subject', 'group', 'in_city'])\n",
    "    temp = temp.rename(columns={'pct_at_level': 'city_std', 'pct_at_level_y': 'city_avg', 'pct_at_level_x': 'pct_at_level'})\n",
    "    del temp_avg\n",
    "    del temp_dev\n",
    "    # create city z score\n",
    "    temp['city_z'] = (temp['pct_at_level'] - temp['city_avg']) / temp['city_std']\n",
    "    temp['above_city_avg'] = temp['pct_at_level'] > temp['city_avg']\n",
    "    print('after city z')\n",
    "    print(temp.shape)\n",
    "\n",
    "    # merge all students result to LI student result\n",
    "    temp_all = temp[temp.group.eq('All Students')]\n",
    "    temp_all = temp_all.rename(columns={'st_z': 'st_z_all', 'city_z': 'city_z_all'})\n",
    "    temp_all = temp_all[temp_all.grade.eq('All')]\n",
    "    temp_li = temp[temp.group.eq('Low-Income')]\n",
    "    temp_li = temp_li.rename(columns={'st_z': 'st_z_li','city_z': 'city_z_li'})\n",
    "    temp_li = temp_li[temp_li.grade.eq('All')]\n",
    "    temp_gap = temp_all.merge(temp_li, on=['year', 'district_id', 'district', 'school_id', 'school', 'subject', 'grade'], how='inner')\n",
    "    del temp_li\n",
    "    del temp_all\n",
    "    # compare school's LI z to the statewide all students z as a 1/0 field (>)\n",
    "    temp_gap['st_gap_close'] = temp_gap['st_z_all'] < temp_gap['st_z_li']\n",
    "    # compare school's LI z to the citywide all students z as a 1/0 field (>)\n",
    "    temp_gap['city_gap_close'] = temp_gap['city_z_all'] < temp_gap['city_z_li']\n",
    "    # join gap close back to main dataframe\n",
    "    temp_gap_st = temp_gap[temp_gap['st_gap_close']]\n",
    "    temp_gap_st = temp_gap_st[['year', 'district_id', 'school_id', 'st_gap_close']].drop_duplicates()\n",
    "    temp_gap_city = temp_gap[temp_gap['city_gap_close']]\n",
    "    temp_gap_city = temp_gap_city[['year','district_id', 'school_id', 'city_gap_close']].drop_duplicates()\n",
    "    temp = temp.merge(temp_gap_st, on=['year', 'district_id', 'school_id'], how='left')\n",
    "    temp = temp.merge(temp_gap_city, on=['year', 'district_id', 'school_id'], how='left')\n",
    "    del temp_gap\n",
    "    del temp_gap_st\n",
    "    del temp_gap_city\n",
    "\n",
    "    # create separate dataframe for previous year's results and join to year+1 (e.g. 2018 will get 2017's z joined)\n",
    "    temp_prev = temp.copy()\n",
    "    temp_prev['prev_year'] = temp_prev['year'].astype('int64') + 1\n",
    "    temp_prev['prev_year'] = temp_prev['prev_year'].astype(str)\n",
    "    temp_prev = temp_prev[['prev_year', 'district_id', 'school_id', 'grade', 'group', 'subject', 'st_z', 'city_z']]\n",
    "    temp_prev = temp_prev.rename(columns={'prev_year': 'year'})\n",
    "    temp = temp.merge(temp_prev, on=['year', 'district_id', 'school_id', 'grade', 'group', 'subject'], suffixes=('', '_prev'), how='left')\n",
    "    del temp_prev\n",
    "    # calculate improvement using an offset to the previous row (current z score - previous z score)\n",
    "    temp['st_imp'] = temp['st_z'] - temp['st_z_prev']\n",
    "    temp['city_imp'] = temp['city_z'] - temp['city_z_prev']\n",
    "\n",
    "    # create improvement state average & state std dev\n",
    "    temp_avg = temp.groupby(['year', 'grade', 'subject', 'group'], as_index = False)['st_imp'].mean()\n",
    "    temp_dev = temp.groupby(['year', 'grade', 'subject', 'group'])['st_imp'].std()\n",
    "    # merge improvment state average & std dev\n",
    "    temp = temp.merge(temp_avg, on=['year', 'grade', 'subject', 'group'])\n",
    "    temp = temp.merge(temp_dev, on=['year', 'grade', 'subject', 'group'])\n",
    "    temp = temp.rename(columns={'st_imp': 'st_std_imp', 'st_imp_y': 'st_avg_imp', 'st_imp_x': 'st_imp'})\n",
    "    del temp_avg\n",
    "    del temp_dev\n",
    "    # create state z score\n",
    "    temp['st_z_imp'] = (temp['st_imp'] - temp['st_avg_imp']) / temp['st_std_imp']\n",
    "\n",
    "    # create city average\n",
    "    temp_avg = temp.groupby(['year', 'grade', 'subject', 'group', 'in_city'], as_index = False)['city_imp'].mean()\n",
    "    # create city std dev\n",
    "    temp_dev = temp.groupby(['year', 'grade', 'subject', 'group', 'in_city'])['city_imp'].std()\n",
    "    # merge city average & std dev\n",
    "    temp = temp.merge(temp_avg, on=['year', 'grade', 'subject', 'group', 'in_city'])\n",
    "    temp = temp.merge(temp_dev, on=['year', 'grade', 'subject', 'group', 'in_city'])\n",
    "    temp = temp.rename(columns={'city_imp': 'city_std_imp', 'city_imp_y': 'city_avg_imp', 'city_imp_x': 'city_imp'})\n",
    "    del temp_avg\n",
    "    del temp_dev\n",
    "    # create city z score\n",
    "    temp['city_z_imp'] = (temp['city_imp'] - temp['city_avg_imp']) / temp['city_std_imp']\n",
    "\n",
    "    # create lists of distinct grade, group_state, subject, year\n",
    "    years = temp.year.unique()\n",
    "    grades = temp.grade.unique()\n",
    "    subjects = temp.subject.unique()\n",
    "    groups = temp.group.unique()\n",
    "    # create quintiles by looping through year/grade/subject/group\n",
    "    temp2 = pd.DataFrame()\n",
    "    for year in years:\n",
    "        for grade in grades:\n",
    "            for subject in subjects:\n",
    "                for group in groups:\n",
    "                    temp3 = temp.loc[(temp['year'] == year) & (temp['grade'] == grade) & (temp['subject'] == subject) & (temp['group'] == group)]\n",
    "                    # create state quintile\n",
    "                    temp3['st_quin'] = pd.qcut(temp3['st_z'], 5, labels=False, duplicates='drop')\n",
    "                    temp3['st_quin'] = temp3['st_quin'] + 1\n",
    "                    temp3['top_20_st'] = temp3['st_quin'] == 5\n",
    "                    # create city quintile\n",
    "                    temp3['city_quin'] = pd.qcut(temp3['city_z'], 5, labels=False, duplicates='drop')\n",
    "                    temp3['city_quin'] = temp3['city_quin'] + 1\n",
    "                    temp3['top_20_city'] = temp3['city_quin'] == 5\n",
    "                    # create improvement state quintile\n",
    "                    temp3['st_quin_imp'] = pd.qcut(temp3['st_z_imp'], 5, labels=False, duplicates='drop')\n",
    "                    temp3['st_quin_imp'] = temp3['st_quin_imp'] + 1\n",
    "                    # create improvement city quintile\n",
    "                    temp3['city_quin_imp'] = pd.qcut(temp3['city_z_imp'], 5, labels=False, duplicates='drop')\n",
    "                    temp3['city_quin_imp'] = temp3['city_quin_imp'] + 1\n",
    "                    temp2 = temp2.append(temp3, ignore_index=True)\n",
    "\n",
    "    df_p = df_p.append(temp2, ignore_index = True, sort = True)\n",
    "    \n",
    "print(df_p['state'].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join grants on state & district_id, and by state, district_id, school_id\n",
    "df_p = df_p.merge(grants_district, on=['state', 'district_id'], suffixes=('', '_grant_district'), how='outer')\n",
    "df_p = df_p.merge(grants_school, on=['state', 'district_id', 'school_id'], suffixes=('', '_grant_school'), how='outer')\n",
    "\n",
    "# join ed champion\n",
    "df_p = df_p.merge(df_champ, on='state', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61850, 4)\n",
      "(50496, 4)\n",
      "  state district_id school_id  max  min  grade5flag  grade8flag\n",
      "0    ca       10017    109835  9.0  1.0         1.0         1.0\n",
      "1    ca       10017    112607  9.0  9.0         NaN         NaN\n",
      "2    ca       10017    118489  9.0  9.0         NaN         NaN\n",
      "3    ca       10017    123968  8.0  1.0         1.0         1.0\n",
      "4    ca       10017    124172  8.0  1.0         1.0         1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# add grade config\n",
    "# create dataframe of distinct state/district/school/grade from enrollment data\n",
    "df_grades = df_e[['state', 'district_id', 'school_id', 'grade']].append(df_p[['state', 'district_id', 'school_id', 'grade']], ignore_index=True, sort=True).drop_duplicates()\n",
    "\n",
    "# if grade = HS/EOC, then grade = '9'\n",
    "df_grades['grade'] = [x if x != 'HS/EOC' else '9' for x in df_grades['grade']]\n",
    "\n",
    "# convert grade to number\n",
    "def toFloat(row, column):\n",
    "    try:\n",
    "        return float(row[column])\n",
    "    except:\n",
    "        return np.nan\n",
    "df_grades['grade'] = df_grades.apply(lambda x: toFloat(x, 'grade'), axis=1)\n",
    "print(df_grades.shape)\n",
    "df_grades = df_grades.dropna(subset=['grade'])\n",
    "print(df_grades.shape)\n",
    "# calculate max grade\n",
    "df_max = df_grades.groupby(['state', 'district_id', 'school_id'], as_index=False)['grade'].max()\n",
    "df_max = df_max.rename(columns={'grade':'max'})\n",
    "# calculate min grade\n",
    "df_min = df_grades.groupby(['state', 'district_id', 'school_id'], as_index=False)['grade'].min()\n",
    "df_min = df_min.rename(columns={'grade':'min'})\n",
    "# calculate grade5? and grade8?\n",
    "df_5 = df_grades[df_grades.grade.eq(5)]\n",
    "df_5['grade5flag'] = 1\n",
    "del df_5['grade']\n",
    "df_8 = df_grades[df_grades.grade.eq(8)]\n",
    "df_8['grade8flag'] = 1\n",
    "del df_8['grade']\n",
    "\n",
    "# merge all together\n",
    "df_grades = df_max.merge(df_min, on=['state', 'district_id', 'school_id'])\n",
    "df_grades = df_grades.merge(df_5, on=['state', 'district_id', 'school_id'], how='left')\n",
    "df_grades = df_grades.merge(df_8, on=['state', 'district_id', 'school_id'], how='left')\n",
    "del df_max\n",
    "del df_min\n",
    "del df_5\n",
    "del df_8\n",
    "print(df_grades.head(5))\n",
    "\n",
    "def gradeConfig(row):\n",
    "    if row['grade5flag'] == 1 and row['grade8flag'] == 1:\n",
    "        if row['max'] <= 8:\n",
    "            return 'ESMS'\n",
    "        else:\n",
    "            return 'ESMSHS'\n",
    "    if row['min'] >= 5:\n",
    "        if row['max'] <= 8:\n",
    "            return 'MS'\n",
    "        else:\n",
    "            return 'MSHS'\n",
    "    if row['max'] <= 7:\n",
    "        return 'ES'\n",
    "    if row['min'] >= 9:\n",
    "        return 'HS'\n",
    "\n",
    "df_grades['grade_config'] = df_grades.apply(lambda x: gradeConfig(x), axis = 1)\n",
    "# ES = if highest grade is <=7\n",
    "# ESMS = if has both grade 5 and 8 and no grade >8\n",
    "# MS = if lowest grade is >=5 and highest grade <=8\n",
    "# MSHS = if lowest grade >=5 and highest grade >=9\n",
    "# ESMSHS = if has grade 5, grade 8 and any grade >=9\n",
    "# HS = if lowest grade >=9 and highest grade <=12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1252700, 87)\n",
      "(1252700, 92)\n",
      "(1699107, 114)\n",
      "(1699107, 119)\n"
     ]
    }
   ],
   "source": [
    "# merge grade config back to enrollment data\n",
    "print(df_e.shape)\n",
    "df_e = df_e.merge(df_grades, on=['state', 'district_id', 'school_id'], how='left')\n",
    "print(df_e.shape)\n",
    "print(df_p.shape)\n",
    "df_p = df_p.merge(df_grades, on=['state', 'district_id', 'school_id'], how='left')\n",
    "print(df_p.shape)\n",
    "del df_grades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join enrollment numbers on year, district_id, school_id, grade, group, maintaining records from both\n",
    "# df = df_p.merge(df_e, on=['year', 'state', 'district_id', 'school_id', 'grade', 'group'], how='outer', suffixes=('_p', '_e'))\n",
    "\n",
    "# print(df.shape)\n",
    "# print(df['state'].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1252700, 92)\n",
      "(1252700, 100)\n"
     ]
    }
   ],
   "source": [
    "# join proficiency metrics needed in dashboards to enrollment file\n",
    "df_scores = df_p[df_p.subject.eq('Composite')]\n",
    "df_scores = df_scores[['year', 'state', 'district_id', 'school_id', 'grade', 'group', 'above_st_avg', 'above_city_avg', 'top_20_st', 'top_20_city', 'city_gap_close', 'st_gap_close', 'city_quin', 'st_quin']].drop_duplicates()\n",
    "print(df_e.shape)\n",
    "df_e = df_e.merge(df_scores, on=['year', 'state', 'district_id', 'school_id', 'grade', 'group'], how='left')\n",
    "print(df_e.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export enrollment and proficiency dataframes\n",
    "# df_e.to_csv('data/finalized/enrollment.csv')\n",
    "# df_p.to_csv('data/finalized/proficiency.csv')\n",
    "df_e.to_csv('data/finalized/ca_enrollment_finalized.csv')\n",
    "df_p.to_csv('data/finalized/ca_proficiency_finalized.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year\n",
      "2015    9229\n",
      "2016    9303\n",
      "2017    9330\n",
      "2018    9344\n",
      "2019    9433\n",
      "Name: school_id, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_p.groupby(['state', 'year', 'grade', 'group'])['school_id'].count().to_csv('temp.csv')\n",
    "print(df_p.groupby(['year'])['school_id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export df\n",
    "# df.to_csv('data/finalized/final.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
