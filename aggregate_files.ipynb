{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize state list\n",
    "states = [\n",
    "    'ca',\n",
    "#     'co',\n",
    "    'dc',\n",
    "#     'ks',\n",
    "    'ga',\n",
    "    'la',\n",
    "    'ma',\n",
    "    'mn',\n",
    "    'mo',\n",
    "    'nj',\n",
    "    'pa',\n",
    "#     'tn',\n",
    "    'tx'\n",
    "]\n",
    "\n",
    "# states=['nj']\n",
    "\n",
    "finalized_path = './data/finalized/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanStrings(row, column):\n",
    "    try:\n",
    "        return str(int(float(row[column])))\n",
    "    except:\n",
    "        return row[column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28840, 6)\n",
      "  district_id school_id in_city charter state  flag\n",
      "0         NaN       NaN     NaN     NaN    la     1\n",
      "1           1         1     NaN     NaN    ma     1\n",
      "2           1         1     NaN     NaN    mn     1\n",
      "3           1        15     NaN     NaN    ma     1\n",
      "4           1         2     NaN     NaN    mn     1\n"
     ]
    }
   ],
   "source": [
    "# import in_city & charter from directory\n",
    "df_directory = pd.read_csv(finalized_path + 'directory_data_combined.csv',dtype={'district_id':str,'school_id':str,'district':str,'school':str,'in_city':str,'charter':str,'state':str})\n",
    "df_directory['state'] = df_directory['state'].str.lower()\n",
    "df_directory['flag'] = 1\n",
    "df_directory = df_directory[['district_id', 'school_id', 'in_city', 'charter', 'state', 'flag']]\n",
    "# apply cleanStrings function to district_id and school_id\n",
    "df_directory['district_id'] = df_directory.apply(lambda x: cleanStrings(x, 'district_id') ,axis=1)\n",
    "df_directory['school_id'] = df_directory.apply(lambda x: cleanStrings(x, 'school_id') ,axis=1)\n",
    "\n",
    "print(df_directory.shape)\n",
    "print(df_directory.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 8)\n",
      "   edchamp_id                      edchamp_name          city state  \\\n",
      "0           1               Boston Schools Fund        Boston    ma   \n",
      "1           2           City Education Partners   San Antonio    tx   \n",
      "2           3                      EdForward DC    Washington    dc   \n",
      "3           4                        Educate 78       Oakland    ca   \n",
      "4           5  New Jersey Children's Foundation        Newark    nj   \n",
      "5           6       New Schools for Baton Rouge   Baton Rouge    la   \n",
      "6           7  Philadelphia Schools Partnership  Philadelphia    pa   \n",
      "7           8                        RedefineED       Atlanta    ga   \n",
      "8           9                    SchoolSmart KC   Kansas City    mo   \n",
      "10         11                  Great MN Schools   Minneapolis    mn   \n",
      "\n",
      "     latitude   longitude first_grant_start launch_year_spring  \n",
      "0   42.370567  -71.026964           9/24/15               2016  \n",
      "1   29.468413  -98.528889            9/1/15               2016  \n",
      "2   38.911936  -77.016719           9/15/16               2017  \n",
      "3   37.786027 -122.223779          12/12/13               2014  \n",
      "4   40.736101  -74.225090            7/1/19               2020  \n",
      "5   30.449240  -91.185607            5/1/16               2017  \n",
      "6   40.001811  -75.117870            8/1/11               2012  \n",
      "7   33.844371  -84.474050            6/1/17               2018  \n",
      "8   39.099700  -94.578600           4/10/17               2018  \n",
      "10  44.977800  -93.265000            1/1/15               2015  \n"
     ]
    }
   ],
   "source": [
    "# import ed champion\n",
    "df_champ = pd.read_csv(finalized_path + 'ed_champions_data.csv', dtype={'edchamp_id':str,'edchamp_name':str,'city':str,'state':str,'latitude':np.float64,'longitude':np.float64,'first_grant_start':str,'launch_year_spring':str})\n",
    "df_champ['state'] = df_champ['state'].str.lower()\n",
    "\n",
    "# remove The Opportunity Trust from ed champ file for now, per Steve\n",
    "df_champ = df_champ[~df_champ.edchamp_name.eq('The Opportunity Trust')]\n",
    "\n",
    "print(df_champ.shape)\n",
    "print(df_champ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1349, 40)\n",
      "0                             Educate 78\n",
      "933                         EdForward DC\n",
      "977                            RedefinEd\n",
      "992          New Schools for Baton Rouge\n",
      "1015                 Boston Schools Fund\n",
      "1066                    Great MN Schools\n",
      "1283                      SchoolSmart KC\n",
      "1298    New Jersey Children's Foundation\n",
      "1302    Philadelphia Schools Partnership\n",
      "1370             City Education Partners\n",
      "Name: educationchampion, dtype: object\n",
      "    grantmerge state educationchampion grantid    grantscope district_id  \\\n",
      "0  matched (3)    ca        Educate 78   11101  School-based       61259   \n",
      "1  matched (3)    ca        Educate 78   11201  School-based       61259   \n",
      "2  matched (3)    ca        Educate 78   11301  School-based       61259   \n",
      "3  matched (3)    ca        Educate 78   11301  School-based       61259   \n",
      "4  matched (3)    ca        Educate 78   11301  School-based       61259   \n",
      "\n",
      "                        stateleaname previousstateleaid schoolgranteeid  \\\n",
      "0  Santa Fe Community School- CLOSED                NaN            1191   \n",
      "1  Santa Fe Community School- CLOSED                NaN            1192   \n",
      "2                    Amethod Schools                NaN            1195   \n",
      "3                    Amethod Schools                NaN            1194   \n",
      "4                    Amethod Schools                NaN            1196   \n",
      "\n",
      "  school_id  ... schooltype                              schoolgrantstrategy  \\\n",
      "0   6002166  ...        New             New Start (new school, new operator)   \n",
      "1   6002166  ...        New             New Start (new school, new operator)   \n",
      "2   6111660  ...   Existing  Improvement (existing school, current operator)   \n",
      "3    129635  ...   Existing  Improvement (existing school, current operator)   \n",
      "4    114868  ...   Existing  Improvement (existing school, current operator)   \n",
      "\n",
      "  endofgrantenrollmentgoal wasanyportionofthetotalgra  \\\n",
      "0                      NaN                        Yes   \n",
      "1                      NaN                        Yes   \n",
      "2                      NaN                         No   \n",
      "3                      NaN                         No   \n",
      "4                      NaN                         No   \n",
      "\n",
      "  portionedamountcommitted portionedamountdisbursed no_id_status    year  \\\n",
      "0                   844.00                   844.00          NaN  2017.0   \n",
      "1                 12000.00                 12000.00          NaN  2016.0   \n",
      "2                  8333.33                  8333.33          NaN  2018.0   \n",
      "3                  8333.33                  8333.33          NaN  2018.0   \n",
      "4                  8333.33                  8333.33          NaN  2018.0   \n",
      "\n",
      "  month start_sy  \n",
      "0   7.0     2018  \n",
      "1   9.0     2017  \n",
      "2   1.0     2018  \n",
      "3   1.0     2018  \n",
      "4   1.0     2018  \n",
      "\n",
      "[5 rows x 40 columns]\n",
      "(1349, 40)\n",
      "(1349, 47)\n"
     ]
    }
   ],
   "source": [
    "# import grant data\n",
    "df_grant = pd.read_csv(finalized_path + 'grants_clean_unifiedForAnalysis.csv',dtype={'grantmerge': str,'state':str,'educationchampion':str,'grantid':str,'grantscope':str,'district_id':str,'stateleaname':str,'previousstateleaid':str,'schoolgranteeid':str,'school_id':str,'stateschoolname':str,'previousstateschoolid':str,'granteeisthesameasgrantben':str,'granteenameifdifferentfrom':str,'leagrantstrategy':str,'strategyenrollmentmax':str,'strategyqualityimprovement':str,'strategyexpansion':str,'strategynewstart':str,'endofgrantleaenrollmentgoal':str,'granttype':str,'supportorganizationsinvolved':str,'levelofedchampinvolvement':str,'duration':str,'startdate':str,'enddate':str,'totalamountcommitted':np.float64,'totalamountdisbursed':np.float64,'otherfundscontributed':str,'notes':str,'schooltype':str,'schoolgrantstrategy':str,'endofgrantenrollmentgoal':np.float64,'wasanyportionofthetotalgra':str,'portionedamountcommitted':np.float64,'portionedamountdisbursed':np.float64,'no_id_status':str}, parse_dates=['startdate', 'enddate'])\n",
    "\n",
    "# apply cleanStrings function to district_id and school_id\n",
    "df_grant['district_id'] = df_grant.apply(lambda x: cleanStrings(x, 'district_id') ,axis=1)\n",
    "df_grant['school_id'] = df_grant.apply(lambda x: cleanStrings(x, 'school_id') ,axis=1)\n",
    "df_grant['educationchampion'] = ['RedefinEd' if x == 'RedefineEd' else x for x in df_grant['educationchampion']]\n",
    "\n",
    "# find start date school year\n",
    "df_grant['year'] = pd.DatetimeIndex(df_grant['startdate']).year\n",
    "df_grant['month'] = pd.DatetimeIndex(df_grant['startdate']).month\n",
    "\n",
    "def calcSY(row):\n",
    "    try:\n",
    "        if row['month'] >= 6:\n",
    "            return row['year'] + 1\n",
    "        else:\n",
    "            return row['year']\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "df_grant['start_sy'] = df_grant.apply(lambda x: calcSY(x), axis = 1)\n",
    "df_grant = df_grant.dropna(subset=['start_sy'])\n",
    "df_grant['start_sy'] = df_grant['start_sy'].astype('int64')\n",
    "\n",
    "# drop records with start date school year > 2020\n",
    "df_grant = df_grant[df_grant['start_sy'] <= 2020]\n",
    "\n",
    "print(df_grant.shape)\n",
    "print(df_grant['educationchampion'].drop_duplicates())\n",
    "print(df_grant.head(5))\n",
    "\n",
    "# join edchamp to grants dataset\n",
    "print(df_grant.shape)\n",
    "df_grant = df_grant.merge(df_champ, on=['state'])\n",
    "print(df_grant.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  state  start_sy\n",
      "0    ca      2014\n",
      "1    dc      2017\n",
      "2    ga      2018\n",
      "3    la      2016\n",
      "4    ma      2016\n",
      "5    mn      2015\n",
      "6    mo      2017\n",
      "7    nj      2020\n",
      "8    pa      2012\n",
      "9    tx      2016\n",
      "  state district_id  start_sy_d\n",
      "0    ca       61259        2018\n",
      "1    ga     7830617        2018\n",
      "2    ga     7830628        2019\n",
      "3    ma         412        2018\n",
      "4    ma         416        2018\n",
      "  state district_id school_id  start_sy_s\n",
      "0    ca       10017    112607        2016\n",
      "1    ca       10017    123968        2016\n",
      "2    ca       10017    124172        2016\n",
      "3    ca       10017    125567        2016\n",
      "4    ca       10017    131581        2016\n"
     ]
    }
   ],
   "source": [
    "# drop null start_sy\n",
    "temp = df_grant.dropna(subset=['start_sy'])\n",
    "\n",
    "# create earliest grant year by state\n",
    "df_grantyear = temp[['state', 'start_sy']].drop_duplicates()\n",
    "df_grantyear = df_grantyear.groupby(['state'], as_index=False)['start_sy'].min()\n",
    "print(df_grantyear)\n",
    "\n",
    "# create earliest grant year by district\n",
    "df_grantyear_d = temp[temp.grantscope.eq('LEA-wide')][['state', 'district_id', 'start_sy']].drop_duplicates()\n",
    "df_grantyear_d = df_grantyear_d.groupby(['state', 'district_id'], as_index=False)['start_sy'].min()\n",
    "df_grantyear_d = df_grantyear_d.rename(columns={'start_sy': 'start_sy_d'})\n",
    "print(df_grantyear_d.head(5))\n",
    "\n",
    "# create earliest grant year by school\n",
    "df_grantyear_s = temp[temp.grantscope.eq('School-based')][['state', 'district_id', 'school_id', 'start_sy']].drop_duplicates()\n",
    "df_grantyear_s = df_grantyear_s.groupby(['state', 'district_id', 'school_id'], as_index=False)['start_sy'].min()\n",
    "df_grantyear_s = df_grantyear_s.rename(columns={'start_sy': 'start_sy_s'})\n",
    "print(df_grantyear_s.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     state district_id  grant_flag_district\n",
      "869     ca       61259                    1\n",
      "983     ga     7830617                    1\n",
      "986     ga     7830628                    1\n",
      "1015    ma         469                    1\n",
      "1018    ma         444                    1\n",
      "  state district_id school_id  grant_flag_school\n",
      "0    ca       61259   6002166                  1\n",
      "2    ca       61259   6111660                  1\n",
      "3    ca       61259    129635                  1\n",
      "4    ca       61259    114868                  1\n",
      "5    ca       10017    112607                  1\n"
     ]
    }
   ],
   "source": [
    "# create grantmaker details\n",
    "\n",
    "# grantee_district_flag\n",
    "grants_district = df_grant[df_grant.grantscope.eq('LEA-wide')][['state', 'district_id']].drop_duplicates()\n",
    "grants_district['grant_flag_district'] = 1\n",
    "grants_district = grants_district.dropna(subset=['district_id'])\n",
    "print(grants_district.head())\n",
    "\n",
    "# grantee_school_flag\n",
    "grants_school = df_grant[df_grant.grantscope.eq('School-based')][['state', 'district_id', 'school_id']].drop_duplicates()\n",
    "grants_school['grant_flag_school'] = 1\n",
    "grants_school = grants_school.dropna(subset=['district_id', 'school_id'])\n",
    "print(grants_school.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  state district_id  grants_district_growth  grants_district_newstart  \\\n",
      "0    ca       61259                       0                         0   \n",
      "1    ga     7830617                       0                         1   \n",
      "2    ga     7830628                       0                         1   \n",
      "3    ma         412                       0                         0   \n",
      "4    ma         416                       1                         0   \n",
      "\n",
      "   grants_district_qa  \n",
      "0                   8  \n",
      "1                   0  \n",
      "2                   0  \n",
      "3                   1  \n",
      "4                   0  \n",
      "  state district_id school_id  grants_school_growth  grants_school_newstart  \\\n",
      "0    ca       10017    112607                    21                       2   \n",
      "1    ca       10017    123968                     9                       0   \n",
      "2    ca       10017    124172                    12                       1   \n",
      "3    ca       10017    125567                     9                       1   \n",
      "4    ca       10017    131581                    15                       8   \n",
      "\n",
      "   grants_school_qa  \n",
      "0                13  \n",
      "1                12  \n",
      "2                 8  \n",
      "3                 2  \n",
      "4                20  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# create grant strategy fields\n",
    "df_grantdetails = df_grant[['state', 'district_id', 'school_id', 'grantscope', 'strategyenrollmentmax', 'strategyexpansion', 'strategynewstart', 'strategyqualityimprovement', ]]\n",
    "\n",
    "df_grantdetails['enrollment_flag'] = [1 if x == 'Y' else 0 for x in df_grantdetails['strategyenrollmentmax']]\n",
    "df_grantdetails['expansion_flag'] = [1 if x == 'Y' else 0 for x in df_grantdetails['strategyexpansion']]\n",
    "df_grantdetails['newstart_flag'] = [1 if x == 'Y' else 0 for x in df_grantdetails['strategynewstart']]\n",
    "df_grantdetails['qi_flag'] = [1 if x == 'Y' else 0 for x in df_grantdetails['strategyqualityimprovement']]\n",
    "df_grantdetails['growth'] = df_grantdetails['enrollment_flag'] + df_grantdetails['expansion_flag']\n",
    "\n",
    "df_grantdetails_d = df_grantdetails[df_grantdetails.grantscope.eq('LEA-wide')]\n",
    "df_grantdetails_s = df_grantdetails[df_grantdetails.grantscope.eq('School-based')]\n",
    "\n",
    "df_grantdetails_d = df_grantdetails_d.groupby(['state', 'district_id'], as_index=False).agg({'growth': 'sum','newstart_flag':'sum', 'qi_flag':'sum'})\n",
    "df_grantdetails_s = df_grantdetails_s.groupby(['state', 'district_id', 'school_id'], as_index=False).agg({'growth': 'sum','newstart_flag':'sum', 'qi_flag':'sum'})\n",
    "\n",
    "df_grantdetails_d = df_grantdetails_d.rename(columns = {\n",
    "    'growth': 'grants_district_growth',\n",
    "    'newstart_flag': 'grants_district_newstart',\n",
    "    'qi_flag': 'grants_district_qa'\n",
    "})\n",
    "\n",
    "df_grantdetails_s = df_grantdetails_s.rename(columns = {\n",
    "    'growth': 'grants_school_growth',\n",
    "    'newstart_flag': 'grants_school_newstart',\n",
    "    'qi_flag': 'grants_school_qa'\n",
    "})\n",
    "\n",
    "print(df_grantdetails_d.head())\n",
    "print(df_grantdetails_s.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(301, 4)\n",
      "  state grade grade_new        file\n",
      "0    ca     1         1  enrollment\n",
      "1    ca     2         2  enrollment\n",
      "2    ca     9    HS/EOC  enrollment\n",
      "3    ca    10    HS/EOC  enrollment\n",
      "4    ca    12    HS/EOC  enrollment\n"
     ]
    }
   ],
   "source": [
    "# import grade map\n",
    "df_grademap = pd.read_csv(finalized_path + 'grade_lookup.csv',dtype={'state':str,'grade':str,'grade_new':str, 'file':str})\n",
    "\n",
    "print(df_grademap.shape)\n",
    "print(df_grademap.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(167, 4)\n",
      "  state       group_state     group_new        file\n",
      "0    ca  African American         Black  enrollment\n",
      "1    ca          Hispanic      Hispanic  enrollment\n",
      "2    ca             White         White  enrollment\n",
      "3    ca           frplk12    Low-Income  enrollment\n",
      "4    ca          totalk12  All Students  enrollment\n"
     ]
    }
   ],
   "source": [
    "# import group map\n",
    "df_groupmap = pd.read_csv(finalized_path + 'group_lookup.csv',dtype={'state':str,'group_state':str,'group_new':str, 'file':str})\n",
    "\n",
    "print(df_groupmap.shape)\n",
    "print(df_groupmap.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84, 4)\n",
      "  state subject subject_new         file\n",
      "0    ca     ELA         ELA  proficiency\n",
      "1    ca    Math        Math  proficiency\n",
      "2    co     ELA         ELA  proficiency\n",
      "3    co    Math        Math  proficiency\n",
      "4    dc     ELA         ELA  proficiency\n"
     ]
    }
   ],
   "source": [
    "# import subject map\n",
    "df_subjectmap = pd.read_csv(finalized_path + 'subject_lookup.csv',dtype={'state':str,'subject':str,'subject_new':str, 'file':str})\n",
    "\n",
    "print(df_subjectmap.shape)\n",
    "print(df_subjectmap.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing ca\n",
      "Pre city map\n",
      "(2235695, 9)\n",
      "Post city map\n",
      "(2235695, 11)\n",
      "Importing dc\n",
      "Pre city map\n",
      "(21606, 9)\n",
      "Post city map\n",
      "(21606, 11)\n",
      "Importing ga\n",
      "Pre city map\n",
      "(111510, 9)\n",
      "Post city map\n",
      "(111510, 11)\n",
      "Importing la\n",
      "Pre city map\n",
      "(214783, 9)\n",
      "Post city map\n",
      "(214783, 11)\n",
      "Importing ma\n",
      "Pre city map\n",
      "(238368, 9)\n",
      "Post city map\n",
      "(238368, 11)\n",
      "Importing mn\n",
      "Pre city map\n",
      "(826404, 9)\n",
      "Post city map\n",
      "(826404, 11)\n",
      "Importing mo\n",
      "Pre city map\n",
      "(130604, 9)\n",
      "Post city map\n",
      "(130604, 11)\n",
      "Importing nj\n",
      "Pre city map\n",
      "(294300, 9)\n",
      "Post city map\n",
      "(294300, 11)\n",
      "Importing pa\n",
      "Pre city map\n",
      "(255283, 9)\n",
      "Post city map\n",
      "(255283, 11)\n",
      "Importing tx\n",
      "Pre city map\n",
      "(1477200, 9)\n",
      "Post city map\n",
      "(1477200, 11)\n",
      "After all appends\n",
      "(5805753, 11)\n",
      "After grade/group map\n",
      "(2795138, 11)\n",
      "After grant year join\n",
      "(2795138, 12)\n",
      "After grant year district join\n",
      "(2795138, 13)\n",
      "After grant year school join\n",
      "(2795138, 14)\n",
      "After ed champ map\n",
      "(2795138, 21)\n",
      "After district grant flag\n",
      "(2795138, 22)\n",
      "After school grant flag\n",
      "(2795138, 23)\n",
      "After district grant details\n",
      "(2795138, 26)\n",
      "After school grant details\n",
      "(2795138, 29)\n",
      "0          pa\n",
      "32387      dc\n",
      "33636      la\n",
      "139188     ma\n",
      "154438     mn\n",
      "213172     tx\n",
      "543879     ca\n",
      "707616     ga\n",
      "1198156    mo\n",
      "1636544    nj\n",
      "Name: state, dtype: object\n",
      "   year state district_id                     district school_id  \\\n",
      "0  2008    pa   100510000  First Phila CS For Literacy      7744   \n",
      "1  2008    pa   100510000  First Phila CS For Literacy      7744   \n",
      "2  2008    pa   100510000  First Phila CS For Literacy      7744   \n",
      "3  2008    pa   100510000  First Phila CS For Literacy      7744   \n",
      "4  2008    pa   100510000  First Phila CS For Literacy      7744   \n",
      "\n",
      "                        school grade         group in_city charter  ...  \\\n",
      "0  First Phila CS For Literacy     1  All Students       1       1  ...   \n",
      "1  First Phila CS For Literacy     2  All Students       1       1  ...   \n",
      "2  First Phila CS For Literacy     3  All Students       1       1  ...   \n",
      "3  First Phila CS For Literacy     4  All Students       1       1  ...   \n",
      "4  First Phila CS For Literacy     5  All Students       1       1  ...   \n",
      "\n",
      "   first_grant_start  launch_year_spring  grant_flag_district  \\\n",
      "0             8/1/11                2012                  NaN   \n",
      "1             8/1/11                2012                  NaN   \n",
      "2             8/1/11                2012                  NaN   \n",
      "3             8/1/11                2012                  NaN   \n",
      "4             8/1/11                2012                  NaN   \n",
      "\n",
      "   grant_flag_school grants_district_growth grants_district_newstart  \\\n",
      "0                1.0                    NaN                      NaN   \n",
      "1                1.0                    NaN                      NaN   \n",
      "2                1.0                    NaN                      NaN   \n",
      "3                1.0                    NaN                      NaN   \n",
      "4                1.0                    NaN                      NaN   \n",
      "\n",
      "  grants_district_qa  grants_school_growth  grants_school_newstart  \\\n",
      "0                NaN                   1.0                     0.0   \n",
      "1                NaN                   1.0                     0.0   \n",
      "2                NaN                   1.0                     0.0   \n",
      "3                NaN                   1.0                     0.0   \n",
      "4                NaN                   1.0                     0.0   \n",
      "\n",
      "  grants_school_qa  \n",
      "0              0.0  \n",
      "1              0.0  \n",
      "2              0.0  \n",
      "3              0.0  \n",
      "4              0.0  \n",
      "\n",
      "[5 rows x 29 columns]\n",
      "(2795138, 29)\n"
     ]
    }
   ],
   "source": [
    "# import enrollment files\n",
    "df_e = pd.DataFrame()\n",
    "\n",
    "for state in states:\n",
    "    try:\n",
    "        temp = pd.read_csv(finalized_path + state + '_enrollment.csv',dtype={'year': str,'district_id': str,'district': str,'school_id': str,'school': str,'grade': str,'group_state': str,'num': np.int64})\n",
    "    except: \n",
    "        print('No enrollment file for ' + state)\n",
    "        continue\n",
    "    temp['state'] = state\n",
    "    print('Importing ' + state)\n",
    "    # apply cleanStrings function to district_id and school_id\n",
    "    temp['district_id'] = temp.apply(lambda x: cleanStrings(x, 'district_id') ,axis=1)\n",
    "    temp['school_id'] = temp.apply(lambda x: cleanStrings(x, 'school_id') ,axis=1)\n",
    "    \n",
    "    print('Pre city map')\n",
    "    print(temp.shape)\n",
    "    # join city file\n",
    "    if state == 'tx':\n",
    "        temp_dir = df_directory[['state', 'district_id', 'in_city', 'charter', 'flag']].drop_duplicates()\n",
    "        temp = temp.merge(temp_dir, on=['state', 'district_id'], how = 'left')\n",
    "        del temp_dir\n",
    "    else:\n",
    "        temp = temp.merge(df_directory, on=['state', 'district_id', 'school_id'], how = 'left')\n",
    "        temp['charter'] = temp.apply(lambda x: '1' if x['state'] == 'dc' and str(x['district_id']).strip() != '1' else x['charter'], axis = 1)\n",
    "        temp['in_city'] = temp.apply(lambda x: '1' if x['state'] == 'dc' else x['in_city'], axis = 1)\n",
    "    del temp['flag']\n",
    "    print('Post city map')\n",
    "    print(temp.shape)\n",
    "    temp['charter'] = temp['charter'].fillna('0')\n",
    "    temp['in_city'] = temp['in_city'].fillna('0')\n",
    "    \n",
    "    df_e = df_e.append(temp, ignore_index = True, sort = True)\n",
    "\n",
    "print('After all appends')\n",
    "print(df_e.shape)\n",
    "# join groupmap and grademap\n",
    "df_e = df_e.merge(df_grademap, on=['state','grade'], how='left')\n",
    "df_e = df_e.merge(df_groupmap, on=['state','group_state'], how='left')\n",
    "df_e[df_e.grade_new.isnull()][['state', 'grade']].drop_duplicates().to_csv('unmatched_grade_enrollment.csv')\n",
    "df_e[df_e.group_new.isnull()][['state', 'group_state']].drop_duplicates().to_csv('unmatched_group_enrollment.csv')\n",
    "df_e = df_e.groupby(['year', 'state', 'district_id', 'district', 'school_id', 'school', 'grade_new', 'group_new', 'in_city', 'charter'], as_index=False)['num'].sum()\n",
    "df_e = df_e.rename(columns={'grade_new': 'grade', 'group_new': 'group'})\n",
    "print('After grade/group map')\n",
    "print(df_e.shape)\n",
    "# join grants data to enrollment data\n",
    "# df_e = df_e.merge(grants_district, on=['state', 'district_id'], suffixes=('', '_grant_district'), how='left')\n",
    "# df_e = df_e.merge(grants_school, on=['state', 'district_id', 'school_id'], suffixes=('', '_grant_school'), how='left')\n",
    "# print('After grant join')\n",
    "# print(df_e.shape)\n",
    "\n",
    "# join grant year\n",
    "df_e = df_e.merge(df_grantyear, on=['state'], how='left')\n",
    "print('After grant year join')\n",
    "print(df_e.shape)\n",
    "\n",
    "# join grant year district\n",
    "df_e = df_e.merge(df_grantyear_d, on=['state', 'district_id'], how='left')\n",
    "print('After grant year district join')\n",
    "print(df_e.shape)\n",
    "\n",
    "# join grant year school\n",
    "df_e = df_e.merge(df_grantyear_s, on=['state', 'district_id', 'school_id'], how='left')\n",
    "print('After grant year school join')\n",
    "print(df_e.shape)\n",
    "\n",
    "# join ed champion\n",
    "df_e = df_e.merge(df_champ, on='state', how='left')\n",
    "print('After ed champ map')\n",
    "print(df_e.shape)\n",
    "\n",
    "# join district grant flag\n",
    "df_e = df_e.merge(grants_district, on=['state', 'district_id'], how='left')\n",
    "print('After district grant flag')\n",
    "print(df_e.shape)\n",
    "\n",
    "# join school grant flag\n",
    "df_e = df_e.merge(grants_school, on=['state', 'district_id', 'school_id'], how='left')\n",
    "print('After school grant flag')\n",
    "print(df_e.shape)\n",
    "\n",
    "# join grant details\n",
    "df_e = df_e.merge(df_grantdetails_d, on=['state', 'district_id'], how='left')\n",
    "print('After district grant details')\n",
    "print(df_e.shape)\n",
    "df_e = df_e.merge(df_grantdetails_s, on=['state', 'district_id', 'school_id'], how='left')\n",
    "print('After school grant details')\n",
    "print(df_e.shape)\n",
    "\n",
    "print(df_e['state'].drop_duplicates())\n",
    "print(df_e.head(5))\n",
    "print(df_e.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ca\n",
      "(709291, 14)\n",
      "After grade lookups\n",
      "(709291, 16)\n",
      "After group lookups\n",
      "(709291, 18)\n",
      "After subject lookups\n",
      "(709291, 20)\n",
      "After roll up\n",
      "(709291, 10)\n",
      "after composite\n",
      "(1069045, 10)\n",
      "after city file\n",
      "(1069045, 12)\n",
      "after state z\n",
      "(1069045, 16)\n",
      "after city z\n",
      "(1069045, 20)\n",
      "After gap closing\n",
      "(1069045, 22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:176: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:177: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:178: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:180: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:181: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:182: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:184: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:185: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:187: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:188: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dc\n",
      "(141645, 14)\n",
      "After grade lookups\n",
      "(141645, 16)\n",
      "After group lookups\n",
      "(64120, 18)\n",
      "After subject lookups\n",
      "(64120, 20)\n",
      "After roll up\n",
      "(28102, 10)\n",
      "after composite\n",
      "(42321, 10)\n",
      "after city file\n",
      "(42321, 12)\n",
      "after state z\n",
      "(42321, 16)\n",
      "after city z\n",
      "(42321, 20)\n",
      "After gap closing\n",
      "(42321, 22)\n",
      "Processing ga\n",
      "(2457838, 13)\n",
      "After grade lookups\n",
      "(2457838, 15)\n",
      "After group lookups\n",
      "(1429539, 17)\n",
      "After subject lookups\n",
      "(1429539, 19)\n",
      "After roll up\n",
      "(685548, 10)\n",
      "after composite\n",
      "(885809, 10)\n",
      "after city file\n",
      "(885809, 12)\n",
      "after state z\n",
      "(885809, 16)\n",
      "after city z\n",
      "(885809, 20)\n",
      "After gap closing\n",
      "(885809, 22)\n",
      "Processing la\n",
      "(616394, 11)\n",
      "After grade lookups\n",
      "(616394, 13)\n",
      "After group lookups\n",
      "(269699, 15)\n",
      "After subject lookups\n",
      "(269699, 17)\n",
      "After roll up\n",
      "(195532, 10)\n",
      "after composite\n",
      "(288257, 10)\n",
      "after city file\n",
      "(288257, 12)\n",
      "after state z\n",
      "(288257, 16)\n",
      "after city z\n",
      "(288257, 20)\n",
      "After gap closing\n",
      "(288257, 22)\n",
      "Processing ma\n",
      "(685406, 13)\n",
      "After grade lookups\n",
      "(685406, 15)\n",
      "After group lookups\n",
      "(329899, 17)\n",
      "After subject lookups\n",
      "(329899, 19)\n",
      "After roll up\n",
      "(319909, 10)\n",
      "after composite\n",
      "(444294, 10)\n",
      "after city file\n",
      "(444294, 12)\n",
      "after state z\n",
      "(444294, 16)\n",
      "after city z\n",
      "(444294, 20)\n",
      "After gap closing\n",
      "(444294, 22)\n",
      "Processing mn\n",
      "(1101076, 13)\n",
      "After grade lookups\n",
      "(1101076, 15)\n",
      "After group lookups\n",
      "(296040, 17)\n",
      "After subject lookups\n",
      "(296040, 19)\n",
      "After roll up\n",
      "(296040, 10)\n",
      "after composite\n",
      "(446773, 10)\n",
      "after city file\n",
      "(446773, 12)\n",
      "after state z\n",
      "(446773, 16)\n",
      "after city z\n",
      "(446773, 20)\n",
      "After gap closing\n",
      "(449119, 22)\n",
      "Processing mo\n",
      "(1724148, 14)\n",
      "After grade lookups\n",
      "(1722183, 16)\n",
      "After group lookups\n",
      "(910577, 18)\n",
      "After subject lookups\n",
      "(910577, 20)\n",
      "After roll up\n",
      "(243051, 10)\n",
      "after composite\n",
      "(345952, 10)\n",
      "after city file\n",
      "(345952, 12)\n",
      "after state z\n",
      "(345952, 16)\n",
      "after city z\n",
      "(345952, 20)\n",
      "After gap closing\n",
      "(345952, 22)\n",
      "Processing nj\n",
      "(323542, 13)\n",
      "After grade lookups\n",
      "(323542, 15)\n",
      "After group lookups\n",
      "(238571, 17)\n",
      "After subject lookups\n",
      "(238571, 19)\n",
      "After roll up\n",
      "(174055, 10)\n",
      "after composite\n",
      "(264129, 10)\n",
      "after city file\n",
      "(264129, 12)\n",
      "after state z\n",
      "(264129, 16)\n",
      "after city z\n",
      "(264129, 20)\n",
      "After gap closing\n",
      "(264129, 22)\n",
      "Processing pa\n",
      "(273271, 13)\n",
      "After grade lookups\n",
      "(273271, 15)\n",
      "After group lookups\n",
      "(138291, 17)\n",
      "After subject lookups\n",
      "(138291, 19)\n",
      "After roll up\n",
      "(138291, 10)\n",
      "after composite\n",
      "(192949, 10)\n",
      "after city file\n",
      "(192949, 12)\n",
      "after state z\n",
      "(192949, 16)\n",
      "after city z\n",
      "(192949, 20)\n",
      "After gap closing\n",
      "(192949, 22)\n",
      "Processing tx\n",
      "(8030965, 13)\n",
      "After grade lookups\n",
      "(8030965, 15)\n",
      "After group lookups\n",
      "(2897457, 17)\n",
      "After subject lookups\n",
      "(2897457, 19)\n",
      "After roll up\n",
      "(2020975, 10)\n",
      "after composite\n",
      "(2840604, 10)\n",
      "after city file\n",
      "(2840604, 12)\n",
      "after state z\n",
      "(2840604, 16)\n",
      "after city z\n",
      "(2840604, 20)\n",
      "After gap closing\n",
      "(2840604, 22)\n",
      "0          ca\n",
      "1069045    dc\n",
      "1111366    ga\n",
      "1997175    la\n",
      "2285452    ma\n",
      "2729746    mn\n",
      "3185812    mo\n",
      "3531764    nj\n",
      "3795893    pa\n",
      "3988949    tx\n",
      "Name: state, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# import proficiency files\n",
    "df_p = pd.DataFrame()\n",
    "df_unjoined_cities = pd.DataFrame()\n",
    "\n",
    "for state in states:\n",
    "    print('Processing ' + state)\n",
    "    try:\n",
    "        temp = pd.read_csv(finalized_path + state + '_proficiency.csv',dtype={'year': str,'district_id': str,'district': str,'school_id': str,'school': str,'grade': str,'group_state': str,'subject': str,'proficient_tf': bool,'num_at_level': np.float64,'num_tested': np.float64,'pct_at_level': np.float64})\n",
    "    except:\n",
    "        print('No proficiency file for ' + state)\n",
    "        continue\n",
    "    # apply cleanStrings function to district_id and school_id\n",
    "    temp['district_id'] = temp.apply(lambda x: cleanStrings(x, 'district_id') ,axis=1)\n",
    "    temp['school_id'] = temp.apply(lambda x: cleanStrings(x, 'school_id') ,axis=1)\n",
    "    temp['state'] = state\n",
    "\n",
    "    # merge subject_map, group_map, and grade_map\n",
    "    print(temp.shape)\n",
    "    temp = temp.merge(df_grademap, on=['state','grade'], how='left')\n",
    "    temp[temp.grade_new.isnull()][['state', 'grade']].drop_duplicates().to_csv('unmatched_grade_proficiency.csv')\n",
    "    temp = temp[~temp.grade_new.isnull()]\n",
    "    print('After grade lookups')\n",
    "    print(temp.shape)\n",
    "    temp = temp.merge(df_groupmap, on=['state','group_state'], how='left')\n",
    "    temp[temp.group_new.isnull()][['state', 'group_state']].drop_duplicates().to_csv('unmatched_group_proficiency.csv')\n",
    "    temp = temp[~temp.group_new.isnull()]\n",
    "    print('After group lookups')\n",
    "    print(temp.shape)\n",
    "    temp = temp.merge(df_subjectmap, on=['state','subject'], how='left')\n",
    "    temp[temp.subject_new.isnull()][['state', 'subject']].drop_duplicates().to_csv('unmatched_subject_proficiency.csv')\n",
    "    temp = temp[~temp.subject_new.isnull()]\n",
    "    print('After subject lookups')\n",
    "    print(temp.shape)\n",
    "    \n",
    "    # roll up results by averaged pct_at_level\n",
    "    temp = temp.groupby(['year', 'state', 'district_id', 'district', 'school_id', 'school', 'grade_new', 'group_new', 'subject_new'], as_index=False)['pct_at_level'].mean()\n",
    "    temp = temp.rename(columns={'grade_new': 'grade', 'group_new': 'group', 'subject_new':'subject'})\n",
    "    print('After roll up')\n",
    "    print(temp.shape)\n",
    "    \n",
    "    # create composite subject by averaging pct_at_level as a simple average of cleaned ELA/Math subjects\n",
    "    temp_comp = temp[temp.subject.isin(['ELA','Math'])]\n",
    "    temp_comp = temp_comp.groupby(['year','state', 'district_id', 'district', 'school_id', 'school', 'grade', 'group'], as_index=False)['pct_at_level'].mean()\n",
    "    temp_comp['subject'] = 'Composite'\n",
    "    temp = temp.append(temp_comp, ignore_index = True)\n",
    "    del temp_comp\n",
    "    print('after composite')\n",
    "    print(temp.shape)\n",
    "    \n",
    "    # join city file\n",
    "    if state == 'tx':\n",
    "        temp_dir = df_directory[['state', 'district_id', 'in_city', 'charter', 'flag']].drop_duplicates()\n",
    "        temp = temp.merge(temp_dir, on=['state', 'district_id'], how = 'left')\n",
    "        del temp_dir\n",
    "    else:\n",
    "        temp = temp.merge(df_directory, on=['state', 'district_id', 'school_id'], how = 'left')\n",
    "        temp['charter'] = temp.apply(lambda x: 1 if x['state'] == 'dc' and x['district_id'].strip() != '1' else x['charter'], axis = 1)\n",
    "        temp['in_city'] = temp.apply(lambda x: 1 if x['state'] == 'dc' else x['in_city'], axis = 1)\n",
    "    # append unjoined records to df_unjoined_cities for Steve\n",
    "    temp[temp.flag != 1].to_csv('unjoined_city_flag.csv')\n",
    "    del temp['flag']\n",
    "    temp['charter'] = temp['charter'].fillna('0')\n",
    "    temp['in_city'] = temp['in_city'].fillna('0')\n",
    "    print('after city file')\n",
    "    print(temp.shape)\n",
    "    # create state average & state std dev\n",
    "    temp_avg = temp.groupby(['year', 'grade', 'subject', 'group'], as_index = False)['pct_at_level'].mean()\n",
    "    temp_dev = temp.groupby(['year', 'grade', 'subject', 'group'])['pct_at_level'].std()\n",
    "    # merge state average & std dev\n",
    "    temp = temp.merge(temp_avg, on=['year', 'grade', 'subject', 'group'])\n",
    "    temp = temp.merge(temp_dev, on=['year', 'grade', 'subject', 'group'])\n",
    "    temp = temp.rename(columns={'pct_at_level': 'st_std', 'pct_at_level_y': 'st_avg', 'pct_at_level_x': 'pct_at_level'})\n",
    "    del temp_avg\n",
    "    del temp_dev\n",
    "    # create state z score\n",
    "    temp['st_z'] = (temp['pct_at_level'] - temp['st_avg']) / temp['st_std']\n",
    "    temp['above_st_avg'] = temp['pct_at_level'] > temp['st_avg']\n",
    "    print('after state z')\n",
    "    print(temp.shape)\n",
    "\n",
    "    # create city average\n",
    "    temp_avg = temp.groupby(['year', 'grade', 'subject', 'group', 'in_city'], as_index = False)['pct_at_level'].mean()\n",
    "    # create city std dev\n",
    "    temp_dev = temp.groupby(['year', 'grade', 'subject', 'group', 'in_city'])['pct_at_level'].std()\n",
    "    # merge city average & std dev\n",
    "    temp = temp.merge(temp_avg, on=['year', 'grade', 'subject', 'group', 'in_city'])\n",
    "    temp = temp.merge(temp_dev, on=['year', 'grade', 'subject', 'group', 'in_city'])\n",
    "    temp = temp.rename(columns={'pct_at_level': 'city_std', 'pct_at_level_y': 'city_avg', 'pct_at_level_x': 'pct_at_level'})\n",
    "    del temp_avg\n",
    "    del temp_dev\n",
    "    # create city z score\n",
    "    temp['city_z'] = (temp['pct_at_level'] - temp['city_avg']) / temp['city_std']\n",
    "    temp['above_city_avg'] = temp['pct_at_level'] > temp['city_avg']\n",
    "    print('after city z')\n",
    "    print(temp.shape)\n",
    "\n",
    "    # merge all students result to LI student result\n",
    "    temp_all = temp[temp.group.eq('All Students')]\n",
    "    temp_all = temp_all.rename(columns={'st_avg': 'st_avg_all', 'city_avg': 'city_avg_all'})\n",
    "    temp_all = temp_all[temp_all.grade.eq('All')]\n",
    "    temp_all = temp_all[temp_all.subject.eq('Composite')]\n",
    "    temp_li = temp[temp.group.eq('Low-Income')]\n",
    "    temp_li = temp_li.rename(columns={'st_avg': 'st_avg_li','city_avg': 'city_avg_li'})\n",
    "    temp_li = temp_li[temp_li.grade.eq('All')]\n",
    "    temp_li = temp_li[temp_li.subject.eq('Composite')]\n",
    "    temp_gap = temp_all.merge(temp_li, on=['year', 'district_id', 'district', 'school_id', 'school', 'subject', 'grade'], how='inner')\n",
    "    del temp_li\n",
    "    del temp_all\n",
    "    # compare school's LI avg to the statewide all students avg as a 1/0 field (>)\n",
    "    temp_gap['st_gap_close'] = temp_gap['st_avg_all'] < temp_gap['pct_at_level_y']\n",
    "    # compare school's LI avg to the citywide all students avg as a 1/0 field (>)\n",
    "    temp_gap['city_gap_close'] = temp_gap['city_avg_all'] < temp_gap['pct_at_level_y']\n",
    "\n",
    "    # join gap close back to main dataframe\n",
    "#     temp_gap_st = temp_gap[temp_gap['st_gap_close']]\n",
    "#     temp_gap_st = temp_gap_st[['year', 'district_id', 'school_id', 'st_gap_close']].drop_duplicates()\n",
    "#     temp_gap_city = temp_gap[temp_gap['city_gap_close']]\n",
    "    temp_gap = temp_gap[['year','district_id', 'school_id', 'st_gap_close', 'city_gap_close']].drop_duplicates()\n",
    "    temp = temp.merge(temp_gap, on=['year', 'district_id', 'school_id'], how='left')\n",
    "#     temp = temp.merge(temp_gap, on=['year', 'district_id', 'school_id'], how='left')\n",
    "    print('After gap closing')\n",
    "    print(temp.shape)\n",
    "#     del temp_gap_st\n",
    "#     del temp_gap_city\n",
    "\n",
    "    # create separate dataframe for previous year's results and join to year+1 (e.g. 2018 will get 2017's z joined)\n",
    "    temp_prev = temp.copy()\n",
    "    temp_prev['prev_year'] = temp_prev['year'].astype('int64') + 1\n",
    "    temp_prev['prev_year'] = temp_prev['prev_year'].astype(str)\n",
    "    temp_prev = temp_prev[['prev_year', 'district_id', 'school_id', 'grade', 'group', 'subject', 'st_z', 'city_z']]\n",
    "    temp_prev = temp_prev.rename(columns={'prev_year': 'year'})\n",
    "    temp = temp.merge(temp_prev, on=['year', 'district_id', 'school_id', 'grade', 'group', 'subject'], suffixes=('', '_prev'), how='left')\n",
    "    del temp_prev\n",
    "    # calculate improvement using an offset to the previous row (current z score - previous z score)\n",
    "    temp['st_imp'] = temp['st_z'] - temp['st_z_prev']\n",
    "    temp['city_imp'] = temp['city_z'] - temp['city_z_prev']\n",
    "\n",
    "    # create improvement state average & state std dev\n",
    "    temp_avg = temp.groupby(['year', 'grade', 'subject', 'group'], as_index = False)['st_imp'].mean()\n",
    "    temp_dev = temp.groupby(['year', 'grade', 'subject', 'group'])['st_imp'].std()\n",
    "    # merge improvment state average & std dev\n",
    "    temp = temp.merge(temp_avg, on=['year', 'grade', 'subject', 'group'])\n",
    "    temp = temp.merge(temp_dev, on=['year', 'grade', 'subject', 'group'])\n",
    "    temp = temp.rename(columns={'st_imp': 'st_std_imp', 'st_imp_y': 'st_avg_imp', 'st_imp_x': 'st_imp'})\n",
    "    del temp_avg\n",
    "    del temp_dev\n",
    "    # create state z score\n",
    "    temp['st_z_imp'] = (temp['st_imp'] - temp['st_avg_imp']) / temp['st_std_imp']\n",
    "\n",
    "    # create city average\n",
    "    temp_avg = temp.groupby(['year', 'grade', 'subject', 'group', 'in_city'], as_index = False)['city_imp'].mean()\n",
    "    # create city std dev\n",
    "    temp_dev = temp.groupby(['year', 'grade', 'subject', 'group', 'in_city'])['city_imp'].std()\n",
    "    # merge city average & std dev\n",
    "    temp = temp.merge(temp_avg, on=['year', 'grade', 'subject', 'group', 'in_city'])\n",
    "    temp = temp.merge(temp_dev, on=['year', 'grade', 'subject', 'group', 'in_city'])\n",
    "    temp = temp.rename(columns={'city_imp': 'city_std_imp', 'city_imp_y': 'city_avg_imp', 'city_imp_x': 'city_imp'})\n",
    "    del temp_avg\n",
    "    del temp_dev\n",
    "    # create city z score\n",
    "    temp['city_z_imp'] = (temp['city_imp'] - temp['city_avg_imp']) / temp['city_std_imp']\n",
    "\n",
    "    # create lists of distinct grade, group_state, subject, year\n",
    "    years = temp.year.unique()\n",
    "    grades = temp.grade.unique()\n",
    "    subjects = temp.subject.unique()\n",
    "    groups = temp.group.unique()\n",
    "    # create quintiles by looping through year/grade/subject/group\n",
    "    temp2 = pd.DataFrame()\n",
    "    for year in years:\n",
    "        for grade in grades:\n",
    "            for subject in subjects:\n",
    "                for group in groups:\n",
    "                    temp3 = temp.loc[(temp['year'] == year) & (temp['grade'] == grade) & (temp['subject'] == subject) & (temp['group'] == group)]\n",
    "                    # create state quintile\n",
    "                    temp3['st_quin'] = pd.qcut(temp3['st_z'], 5, labels=False, duplicates='drop')\n",
    "                    temp3['st_quin'] = temp3['st_quin'] + 1\n",
    "                    temp3['top_20_st'] = temp3['st_quin'] == 5\n",
    "                    # create city quintile\n",
    "                    temp3['city_quin'] = pd.qcut(temp3['city_z'], 5, labels=False, duplicates='drop')\n",
    "                    temp3['city_quin'] = temp3['city_quin'] + 1\n",
    "                    temp3['top_20_city'] = temp3['city_quin'] == 5\n",
    "                    # create improvement state quintile\n",
    "                    temp3['st_quin_imp'] = pd.qcut(temp3['st_z_imp'], 5, labels=False, duplicates='drop')\n",
    "                    temp3['st_quin_imp'] = temp3['st_quin_imp'] + 1\n",
    "                    # create improvement city quintile\n",
    "                    temp3['city_quin_imp'] = pd.qcut(temp3['city_z_imp'], 5, labels=False, duplicates='drop')\n",
    "                    temp3['city_quin_imp'] = temp3['city_quin_imp'] + 1\n",
    "                    temp2 = temp2.append(temp3, ignore_index=True)\n",
    "\n",
    "    df_p = df_p.append(temp2, ignore_index = True, sort = True)\n",
    "    \n",
    "print(df_p['state'].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After grant year join\n",
      "(7216551, 39)\n",
      "After grant year district join\n",
      "(7216551, 40)\n",
      "After grant year school join\n",
      "(7216551, 41)\n",
      "After district grant flag\n",
      "(7216551, 49)\n",
      "After school grant flag\n",
      "(7216551, 50)\n",
      "After district grant details\n",
      "(7216551, 53)\n",
      "After school grant details\n",
      "(7216551, 56)\n"
     ]
    }
   ],
   "source": [
    "# join grants on state & district_id, and by state, district_id, school_id\n",
    "# df_p = df_p.merge(grants_district, on=['state', 'district_id'], suffixes=('', '_grant_district'), how='outer')\n",
    "# df_p = df_p.merge(grants_school, on=['state', 'district_id', 'school_id'], suffixes=('', '_grant_school'), how='outer')\n",
    "\n",
    "# join grant year\n",
    "df_p = df_p.merge(df_grantyear, on=['state'], how='left')\n",
    "print('After grant year join')\n",
    "print(df_p.shape)\n",
    "\n",
    "# join grant year district\n",
    "df_p = df_p.merge(df_grantyear_d, on=['state', 'district_id'], how='left')\n",
    "print('After grant year district join')\n",
    "print(df_p.shape)\n",
    "\n",
    "# join grant year school\n",
    "df_p = df_p.merge(df_grantyear_s, on=['state', 'district_id', 'school_id'], how='left')\n",
    "print('After grant year school join')\n",
    "print(df_p.shape)\n",
    "\n",
    "# join ed champion\n",
    "df_p = df_p.merge(df_champ, on='state', how='left')\n",
    "\n",
    "# join district grant flag\n",
    "df_p = df_p.merge(grants_district, on=['state', 'district_id'], how='left')\n",
    "print('After district grant flag')\n",
    "print(df_p.shape)\n",
    "\n",
    "# join school grant flag\n",
    "df_p = df_p.merge(grants_school, on=['state', 'district_id', 'school_id'], how='left')\n",
    "print('After school grant flag')\n",
    "print(df_p.shape)\n",
    "\n",
    "# join grant details\n",
    "df_p = df_p.merge(df_grantdetails_d, on=['state', 'district_id'], how='left')\n",
    "print('After district grant details')\n",
    "print(df_p.shape)\n",
    "df_p = df_p.merge(df_grantdetails_s, on=['state', 'district_id', 'school_id'], how='left')\n",
    "print('After school grant details')\n",
    "print(df_p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(163531, 4)\n",
      "(163531, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  state district_id school_id  max  min  grade5flag  grade8flag grade_config\n",
      "0    ca       10017    109835  9.0  1.0         1.0         1.0       ESMSHS\n",
      "1    ca       10017    112607  9.0  9.0         NaN         NaN           HS\n",
      "2    ca       10017    118489  9.0  9.0         NaN         NaN           HS\n",
      "3    ca       10017    123968  8.0  1.0         1.0         1.0         ESMS\n",
      "4    ca       10017    124172  8.0  1.0         1.0         1.0         ESMS\n",
      "grade_config\n",
      "ES        17870\n",
      "ESMS       2915\n",
      "ESMSHS     2925\n",
      "HS         6426\n",
      "MS         3162\n",
      "MSHS       4660\n",
      "Name: state, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# MN - schoolid 50 districtId 177 Wyndam Senior High\n",
    "# CA - schoolid 118380 districtid 69484 Christopher High\n",
    "# LA - schoolid 17102 districtid 17 Woodlawn High School\n",
    "# TX - schoolid 200901001 districtid 200901 Balanger High School\n",
    "# PA - schoolid 6793 districtid 103026852 North Allegheny\n",
    "\n",
    "# add grade config\n",
    "# create dataframe of distinct state/district/school/grade from enrollment data\n",
    "df_grades = df_e[['state', 'district_id', 'school_id', 'grade']].append(df_p[['state', 'district_id', 'school_id', 'grade']], ignore_index=True, sort=True).drop_duplicates()\n",
    "\n",
    "# df_grades = df_grades[df_grades.state.eq('mn') & df_grades.school_id.eq('50') & df_grades.district_id.eq('177')]\n",
    "\n",
    "#drop all grades records\n",
    "df_grades = df_grades[~df_grades.grade.eq('All')]\n",
    "\n",
    "# if grade = HS/EOC, then grade = '9'\n",
    "df_grades['grade'] = [x if x != 'HS/EOC' else '9' for x in df_grades['grade']]\n",
    "\n",
    "df_grades = df_grades.drop_duplicates()\n",
    "\n",
    "# convert grade to number\n",
    "def toFloat(row, column):\n",
    "    try:\n",
    "        return float(row[column])\n",
    "    except:\n",
    "        return np.nan\n",
    "df_grades['grade'] = df_grades.apply(lambda x: toFloat(x, 'grade'), axis=1)\n",
    "print(df_grades.shape)\n",
    "\n",
    "df_grades = df_grades.dropna(subset=['grade'])\n",
    "print(df_grades.shape)\n",
    "# calculate max grade\n",
    "df_max = df_grades.groupby(['state', 'district_id', 'school_id'], as_index=False)['grade'].max()\n",
    "df_max = df_max.rename(columns={'grade':'max'})\n",
    "# calculate min grade\n",
    "df_min = df_grades.groupby(['state', 'district_id', 'school_id'], as_index=False)['grade'].min()\n",
    "df_min = df_min.rename(columns={'grade':'min'})\n",
    "# calculate grade5? and grade8?\n",
    "df_5 = df_grades[df_grades.grade.eq(5)]\n",
    "df_5['grade5flag'] = 1\n",
    "del df_5['grade']\n",
    "df_8 = df_grades[df_grades.grade.eq(8)]\n",
    "df_8['grade8flag'] = 1\n",
    "del df_8['grade']\n",
    "\n",
    "# merge all together\n",
    "df_grades = df_max.merge(df_min, on=['state', 'district_id', 'school_id'])\n",
    "df_grades = df_grades.merge(df_5, on=['state', 'district_id', 'school_id'], how='left')\n",
    "df_grades = df_grades.merge(df_8, on=['state', 'district_id', 'school_id'], how='left')\n",
    "del df_max\n",
    "del df_min\n",
    "del df_5\n",
    "del df_8\n",
    "\n",
    "def gradeConfig(row):\n",
    "    if row['grade5flag'] == 1 and row['grade8flag'] == 1:\n",
    "        if row['max'] <= 8:\n",
    "            return 'ESMS'\n",
    "        else:\n",
    "            return 'ESMSHS'\n",
    "    if row['min'] >= 5:\n",
    "        if row['max'] <= 8:\n",
    "            return 'MS'\n",
    "        elif row['min'] >= 9:\n",
    "            return 'HS'\n",
    "        else:\n",
    "            return 'MSHS'\n",
    "    if row['max'] <= 7:\n",
    "        return 'ES'\n",
    "    if row['state'] == 'nj' and row['school_id'] == '300' and row['district_id'] == '1431':\n",
    "        return 'ESMS'\n",
    "\n",
    "df_grades['grade_config'] = df_grades.apply(lambda x: gradeConfig(x), axis = 1)\n",
    "print(df_grades.head(5))\n",
    "df_grades[df_grades['grade_config'].isnull()].to_csv('unmatched_grade_config.csv')\n",
    "# ES = if highest grade is <=7\n",
    "# ESMS = if has both grade 5 and 8 and no grade >8\n",
    "# MS = if lowest grade is >=5 and highest grade <=8\n",
    "# MSHS = if lowest grade >=5 and highest grade >=9\n",
    "# ESMSHS = if has grade 5, grade 8 and any grade >=9\n",
    "# HS = if lowest grade >=9 and highest grade <=12\n",
    "print(df_grades.groupby(['grade_config'])['state'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2795138, 29)\n",
      "(2795138, 34)\n",
      "(7216551, 56)\n",
      "(7216551, 61)\n"
     ]
    }
   ],
   "source": [
    "# merge grade config back to enrollment data\n",
    "print(df_e.shape)\n",
    "df_e = df_e.merge(df_grades, on=['state', 'district_id', 'school_id'], how='left')\n",
    "df_e['grade_config'] = df_e['grade_config'].fillna('Unknown')\n",
    "print(df_e.shape)\n",
    "print(df_p.shape)\n",
    "df_p = df_p.merge(df_grades, on=['state', 'district_id', 'school_id'], how='left')\n",
    "df_p['grade_config'] = df_p['grade_config'].fillna('Unknown')\n",
    "print(df_p.shape)\n",
    "del df_grades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join enrollment numbers on year, district_id, school_id, grade, group, maintaining records from both\n",
    "# df = df_p.merge(df_e, on=['year', 'state', 'district_id', 'school_id', 'grade', 'group'], how='outer', suffixes=('_p', '_e'))\n",
    "\n",
    "# print(df.shape)\n",
    "# print(df['state'].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2795138, 34)\n",
      "(2796620, 42)\n"
     ]
    }
   ],
   "source": [
    "# join proficiency metrics needed in dashboards to enrollment file\n",
    "df_scores = df_p[df_p.subject.eq('Composite')]\n",
    "df_scores = df_scores[['year', 'state', 'district_id', 'school_id', 'grade', 'group', 'above_st_avg', 'above_city_avg', 'top_20_st', 'top_20_city', 'city_gap_close', 'st_gap_close', 'city_quin', 'st_quin']].drop_duplicates()\n",
    "print(df_e.shape)\n",
    "df_e = df_e.merge(df_scores, on=['year', 'state', 'district_id', 'school_id', 'grade', 'group'], how='left')\n",
    "print(df_e.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state\n",
      "ca    3949\n",
      "dc     101\n",
      "ga     250\n",
      "la     657\n",
      "ma     120\n",
      "mn     251\n",
      "mo     176\n",
      "nj      89\n",
      "tx    5511\n",
      "Name: school_id, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# qa gap closing\n",
    "temp = df_e[df_e.st_gap_close.eq(True) | df_e.city_gap_close.eq(True)]\n",
    "print(temp.groupby(['state']).school_id.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export enrollment and proficiency dataframes\n",
    "# df_e.to_csv('data/finalized/enrollment.csv')\n",
    "# df_p.to_csv('data/finalized/proficiency.csv')\n",
    "df_e.to_csv('data/finalized/enrollment_finalized.csv')\n",
    "df_p.to_csv('data/finalized/proficiency_finalized.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export grants data\n",
    "df_grant.to_csv('data/finalized/grants_finalized.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_p.groupby(['state', 'year', 'grade', 'group'])['school_id'].count().to_csv('temp.csv')\n",
    "# print(df_p.groupby(['year'])['school_id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export df\n",
    "# df.to_csv('data/finalized/final.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
